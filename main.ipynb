{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. detect people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on: https://www.youtube.com/watch?v=Pb3opEFP94U&t=813s\n",
    "# based on: https://colab.research.google.com/drive/1x-eMvFQTLBTr7ho9ZlYkHF0NmyUyAlxT?usp=sharing#scrollTo=Z_pe5XFayoHP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.structures import Boxes\n",
    "from detectron2.structures import Keypoints\n",
    "from PIL import Image\n",
    "from SVM import *\n",
    "\n",
    "import detectron2\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(mode):\n",
    "    \"\"\"\n",
    "    Method initializing a detector with a config file\n",
    "\n",
    "    :param: mode: Select work mode (Object Detection, Keypoint Extraction)\n",
    "\n",
    "    :return predictor and cfg objects\n",
    "    \"\"\"\n",
    "\n",
    "    if mode == \"OD\":\n",
    "        cfg_od = get_cfg()\n",
    "        cfg_od.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "        cfg_od.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "\n",
    "        cfg_od.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "        cfg_od.MODEL.DEVICE = \"cpu\"\n",
    "        predictor_od = DefaultPredictor(cfg_od)\n",
    "\n",
    "        return predictor_od, cfg_od\n",
    "\n",
    "    elif mode == \"KP\":\n",
    "        cfg_kp = get_cfg()\n",
    "        cfg_kp.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg_kp.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "        cfg_kp.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "        cfg_kp.MODEL.DEVICE = \"cpu\"\n",
    "        predictor_kp = DefaultPredictor(cfg_kp)\n",
    "\n",
    "        return predictor_kp, cfg_kp\n",
    "\n",
    "predictor_od, cfg_od = __init__(mode=\"OD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function responsible for detected class reduction to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseOneClassFromAllDetected(initialPredictions, image):\n",
    "    \"\"\"\n",
    "    Method responsible for reducing detected object classes to one particular\n",
    "\n",
    "    :param: initialPredictions: predictions produced by self.predictor which is DefaultPredictor(self.cfg)\n",
    "    :param: image: image to be processed\n",
    "    \"\"\"\n",
    "\n",
    "    classes = initialPredictions[\"instances\"].pred_classes\n",
    "    scores = initialPredictions[\"instances\"].scores\n",
    "    boxes = initialPredictions[\"instances\"].pred_boxes\n",
    "\n",
    "    index_to_keep = (classes == 0).nonzero().flatten().tolist()\n",
    "\n",
    "    classes_filtered = torch.tensor(np.take(classes.cpu().numpy(), index_to_keep))\n",
    "    scores_filtered = torch.tensor(np.take(scores.cpu().numpy(), index_to_keep))\n",
    "    boxes_filtered = Boxes(\n",
    "        torch.tensor(np.take(boxes.tensor.cpu().numpy(), index_to_keep, axis=0))\n",
    "    )\n",
    "\n",
    "    obj = detectron2.structures.Instances(\n",
    "        image_size=(image.shape[0], image.shape[1])\n",
    "    )\n",
    "    obj.set(\"pred_classes\", classes_filtered)\n",
    "    obj.set(\"scores\", scores_filtered)\n",
    "    obj.set(\"pred_boxes\", boxes_filtered)\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(imagePath, changeColorMode=True):\n",
    "    \"\"\"\n",
    "    Method responsible for loading an image\n",
    "\n",
    "    :param: imagePath: path to the image\n",
    "    :param: changeColorMode: change BGR to RGB, useful when using both cv2 and matplotlib\n",
    "\n",
    "    :return image object\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.imread(imagePath)\n",
    "    if changeColorMode == True:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return image\n",
    "\n",
    "image = loadImage(imagePath=\"images/cross_walk_she.png\", changeColorMode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform detection and make prediction boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performDetection(predictor, image, classReduction):\n",
    "    \"\"\"\n",
    "    Method performing actual detection\n",
    "\n",
    "    :param: predictor: predictor object\n",
    "    :param: image: image object\n",
    "    :param: classReduction: enables class reduction to one\n",
    "\n",
    "\n",
    "    :return prediction, (optionally) new_predictions and prediction boxes objects\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = predictor(image)\n",
    "\n",
    "    if classReduction == True:\n",
    "        new_predictions = chooseOneClassFromAllDetected(initialPredictions=predictions, image=image)\n",
    "        prediction_boxes = [x.numpy() for x in list(new_predictions.pred_boxes)]\n",
    "\n",
    "        return predictions, new_predictions, prediction_boxes\n",
    "\n",
    "    elif classReduction == False:\n",
    "\n",
    "        return predictions\n",
    "\n",
    "predictions_od, new_predictions_od, prediction_od_boxes = performDetection(predictor=predictor_od, image=image, classReduction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make visualization part and extract image with boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_od = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_od.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "output_od = viz_od.draw_instance_predictions(new_predictions_od.to(\"cpu\"))\n",
    "\n",
    "image_with_boxes = output_od.get_image()[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.imshow(image_with_boxes)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. cut part of the image from bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on: https://stackoverflow.com/questions/68008935/crop-image-using-pred-boxes-coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function responsible for cropping part of an image defined by bounding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImageByBoundingBox(image, box):\n",
    "    \"\"\"\n",
    "    Function responsible for cropping part of an image defined by bounding box coordinates\n",
    "\n",
    "    :param: image: image to be processed\n",
    "    :param: box: numpy array with four box coordinates\n",
    "\n",
    "    return: cropped image object\n",
    "    \"\"\"\n",
    "\n",
    "    x_top_left = box[0]\n",
    "    y_top_left = box[1]\n",
    "    x_bottom_right = box[2]\n",
    "    y_bottom_right = box[3]\n",
    "\n",
    "    if type(image) == np.ndarray:\n",
    "        image = Image.fromarray(image)\n",
    "    crop_img = image.crop((int(x_top_left), int(y_top_left), int(x_bottom_right), int(y_bottom_right)))\n",
    "\n",
    "    if type(image) == Image.Image:\n",
    "        crop_img = np.array(crop_img)\n",
    "\n",
    "    return crop_img, (x_top_left, y_top_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform exemplary cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 0\n",
    "image_cropped, cropped_image_coordinates = cropImageByBoundingBox(image, prediction_od_boxes[image_index])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.imshow(image_cropped)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. make individual skeletonization for each cropped image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure another detector (keypoint extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_kp, cfg_kp = __init__(mode=\"KP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_kp = performDetection(predictor=predictor_kp, image=image_cropped, classReduction=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function to filter detections to take only the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseIndexOfBestKeypointInstanceFromAllDetected(predictions):\n",
    "    \"\"\"\n",
    "    Method responsible for choosing the best (the longest in the sense of euclidean distance) detection instance\n",
    "\n",
    "    :param: predictions: predictions produced by self.predictor which is DefaultPredictor(self.cfg)\n",
    "\n",
    "    return index of the best (the longest in the sense of euclidean distance) prediction\n",
    "    \"\"\"\n",
    "\n",
    "    # index = np.array([predictions[\"instances\"][i].pred_keypoints.numpy().sum() for i in range(len(predictions[\"instances\"].pred_keypoints.numpy()))])\n",
    "\n",
    "    length = len(predictions[\"instances\"].pred_keypoints.numpy())\n",
    "    [predictions[\"instances\"][i].pred_keypoints.numpy().sum() for i in range(length)]\n",
    "\n",
    "    initial_predictions_all = predictions[\"instances\"].pred_keypoints.numpy()\n",
    "    index = np.array([])\n",
    "\n",
    "    for prediction in initial_predictions_all:\n",
    "        sum = 0\n",
    "        for i in range(len(prediction)-1):\n",
    "            sum += np.linalg.norm(prediction[i] - prediction[i+1])\n",
    "        index = np.append(index, sum)\n",
    "\n",
    "    if len(index) > 0:\n",
    "        index_of_value_to_keep = np.argmax(index)\n",
    "    else:\n",
    "        index_of_value_to_keep = 0\n",
    "\n",
    "    return int(index_of_value_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_kp = Visualizer(image_cropped[:, :, ::-1], metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "viz_kp_dots = Visualizer(image_cropped[:, :, ::-1], metadata=MetadataCatalog.get(cfg_od.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "index = chooseIndexOfBestKeypointInstanceFromAllDetected(predictions=predictions_kp)\n",
    "if index == 0:\n",
    "    output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "    output_kp_dots = viz_kp_dots.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "else:\n",
    "    output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"][index].to(\"cpu\"))\n",
    "    output_kp_dots = viz_kp_dots.draw_instance_predictions(predictions_kp[\"instances\"][index].to(\"cpu\"))\n",
    "image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "image_skeletonized_dots = output_kp_dots.get_image()[:, :, ::-1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 8))\n",
    "ax[0].imshow(image_skeletonized)\n",
    "ax[1].imshow(image_skeletonized_dots)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems that detecting people and making skeletons on a scene image (the initial one) gives better accuracy skeletonization\n",
    "# compared to detecting people and making skeletonization on individual people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. project individual masks on the initial picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projecion without coordinates correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_kp = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "index = chooseIndexOfBestKeypointInstanceFromAllDetected(predictions=predictions_kp)\n",
    "if index == 0:\n",
    "    output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "else:\n",
    "    output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"][index].to(\"cpu\"))\n",
    "image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image_skeletonized)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projecion with coordinates correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctIndividualSkeletonCoordinates(initialPredictions, image, croppedImageCoordinates):\n",
    "    \"\"\"\n",
    "    Method responsible for correction of individual detection (box, keypoints) coordinates to match initial picture position\n",
    "\n",
    "    :param: initialPredictions: predictions produced by self.predictor which is DefaultPredictor(self.cfg)\n",
    "    :param: image: cropped image\n",
    "    :param: croppedImageCoordinates: cooridnates of the cropped image on the initiial one\n",
    "\n",
    "    return corrected predictions (box, keypoints)\n",
    "    \"\"\"\n",
    "\n",
    "    boxes = initialPredictions[\"instances\"].pred_boxes\n",
    "    boxes_filtered = boxes.tensor.cpu().numpy().copy()\n",
    "    boxes_filtered[:,0] += croppedImageCoordinates[0]\n",
    "    boxes_filtered[:,2] += croppedImageCoordinates[0]\n",
    "    boxes_filtered[:,1] += croppedImageCoordinates[1]\n",
    "    boxes_filtered[:,3] += croppedImageCoordinates[1]\n",
    "\n",
    "    keypoints = initialPredictions[\"instances\"].pred_keypoints\n",
    "    keypoints_filtered = keypoints.cpu().numpy().copy()\n",
    "    keypoints_filtered[:,:,0] += croppedImageCoordinates[0]\n",
    "    keypoints_filtered[:,:,1] += croppedImageCoordinates[1]\n",
    "\n",
    "    scores = initialPredictions[\"instances\"].scores\n",
    "\n",
    "    boxes_filtered = Boxes(torch.tensor(boxes_filtered))\n",
    "    keypoints_filtered = torch.tensor(keypoints_filtered)\n",
    "\n",
    "    obj = detectron2.structures.Instances(image_size=(image.shape[0], image.shape[1]))\n",
    "    obj.set(\"pred_boxes\", boxes_filtered)\n",
    "    obj.set(\"pred_keypoints\", keypoints_filtered)\n",
    "    obj.set(\"scores\", scores)\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = correctIndividualSkeletonCoordinates(initialPredictions=predictions_kp, image=image_cropped, croppedImageCoordinates=cropped_image_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_kp = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "\n",
    "if index == 0:\n",
    "    output_kp = viz_kp.draw_instance_predictions(new_preds.to(\"cpu\"))\n",
    "else:\n",
    "    output_kp = viz_kp.draw_instance_predictions(new_preds[index].to(\"cpu\"))\n",
    "image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image_skeletonized)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineAllPredictionsTogether(predictionsDict):\n",
    "    \"\"\"\n",
    "    Method responsible for combining all predictions from individual images into one\n",
    "\n",
    "    :param: predictionsDict: dictionary with predictions for each image\n",
    "\n",
    "    return one combined prediction instance object\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_people = len(predictionsDict.keys())\n",
    "    pred_sum = predictionsDict[0]\n",
    "    boxes_sum = pred_sum.pred_boxes.tensor.cpu().numpy().copy()\n",
    "    keypoints_sum = pred_sum.pred_keypoints.cpu().numpy().copy()\n",
    "    scores_sum = pred_sum.scores.cpu().numpy().copy()\n",
    "\n",
    "    if number_of_people > 1:\n",
    "        for i in range(1, number_of_people-1):\n",
    "            pred = predictionsDict[i]\n",
    "            boxes = pred.pred_boxes.tensor.cpu().numpy().copy()\n",
    "            keypoints = pred.pred_keypoints.cpu().numpy().copy()\n",
    "            scores = pred.scores.cpu().numpy().copy()\n",
    "\n",
    "            boxes_sum = np.vstack([boxes_sum, boxes])\n",
    "            keypoints_sum = np.vstack([keypoints_sum, keypoints])\n",
    "            scores_sum = np.append(scores_sum, scores)\n",
    "\n",
    "    boxes_sum = Boxes(torch.tensor(boxes_sum))\n",
    "    keypoints_sum = torch.tensor(keypoints_sum)\n",
    "\n",
    "    obj = detectron2.structures.Instances(image_size=(image.shape[0], image.shape[1]))\n",
    "    obj.set(\"pred_boxes\", boxes_sum)\n",
    "    obj.set(\"pred_keypoints\", keypoints_sum)\n",
    "    obj.set(\"scores\", scores_sum)\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put steps 1-4 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# prepare detectors\n",
    "## initialize OD detector\n",
    "predictor_od, cfg_od = __init__(mode=\"OD\")\n",
    "\n",
    "## initialize KP detector\n",
    "predictor_kp, cfg_kp = __init__(mode=\"KP\")\n",
    "\n",
    "# 0. load an image\n",
    "imagePath = \"images/Pedestrian-Deaths-India-Road-Fatalities-India-1280x720.jpeg\"\n",
    "image = loadImage(imagePath=imagePath, changeColorMode=True)\n",
    "\n",
    "# 1. perform detection and make prediction boxes\n",
    "(\n",
    "    predictions_od,\n",
    "    reduced_predictions_od,\n",
    "    prediction_od_boxes,\n",
    ") = performDetection(\n",
    "    predictor=predictor_od, image=image, classReduction=True\n",
    ")\n",
    "## make visualization part\n",
    "viz_od = Visualizer(\n",
    "    image[:, :, ::-1],\n",
    "    metadata=MetadataCatalog.get(cfg_od.DATASETS.TRAIN[0]),\n",
    "    instance_mode=ColorMode.IMAGE,\n",
    ")\n",
    "output_od = viz_od.draw_instance_predictions(reduced_predictions_od.to(\"cpu\"))\n",
    "image_with_boxes = output_od.get_image()[:, :, ::-1]\n",
    "\n",
    "number_of_people = len(reduced_predictions_od)\n",
    "predictions_kp_all = {}\n",
    "images_kp_all = {}\n",
    "image_final = image.copy()\n",
    "\n",
    "for person_index in range(number_of_people):\n",
    "    # 2. cut part of the image from bounding boxes\n",
    "    image_cropped, cropped_image_coordinates = cropImageByBoundingBox(\n",
    "        image=image, box=prediction_od_boxes[person_index]\n",
    "    )\n",
    "\n",
    "    # 3. make individual skeletonization for the cropped image\n",
    "    ## perform detection\n",
    "    predictions_kp = performDetection(\n",
    "        predictor=predictor_kp, image=image_cropped, classReduction=False\n",
    "    )\n",
    "    ## make visualization part\n",
    "    viz_kp = Visualizer(\n",
    "        image_cropped[:, :, ::-1],\n",
    "        metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]),\n",
    "        instance_mode=ColorMode.IMAGE,\n",
    "    )\n",
    "    index = chooseIndexOfBestKeypointInstanceFromAllDetected(predictions=predictions_kp)\n",
    "    if index == 0:\n",
    "        output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "    else:\n",
    "        output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"][index].to(\"cpu\"))\n",
    "    image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "\n",
    "    # 4. project individual mask on the initial picture\n",
    "    corrected_predictions = correctIndividualSkeletonCoordinates(\n",
    "        initialPredictions=predictions_kp,\n",
    "        image=image_cropped,\n",
    "        croppedImageCoordinates=cropped_image_coordinates,\n",
    "    )\n",
    "    ## make visualization part\n",
    "    viz_kp = Visualizer(\n",
    "        image[:, :, ::-1],\n",
    "        metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]),\n",
    "        instance_mode=ColorMode.IMAGE,\n",
    "    )\n",
    "    if index == 0:\n",
    "        output_kp = viz_kp.draw_instance_predictions(corrected_predictions.to(\"cpu\"))\n",
    "    else:\n",
    "        output_kp = viz_kp.draw_instance_predictions(corrected_predictions[index].to(\"cpu\"))\n",
    "    image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "    ## combine all results\n",
    "    if index == 0:\n",
    "      predictions_kp_all[person_index] = corrected_predictions.to(\"cpu\")\n",
    "    else:\n",
    "      predictions_kp_all[person_index] = corrected_predictions[index].to(\"cpu\")\n",
    "\n",
    "    images_kp_all[person_index] = image_skeletonized\n",
    "\n",
    "final_predictions = combineAllPredictionsTogether(predictionsDict=predictions_kp_all)\n",
    "viz_kp = Visualizer(\n",
    "        image[:, :, ::-1],\n",
    "        metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]),\n",
    "        instance_mode=ColorMode.IMAGE,\n",
    ")\n",
    "output_sum = viz_kp.draw_instance_predictions(final_predictions.to(\"cpu\"))\n",
    "image_sum = output_sum.get_image()[:, :, ::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image_sum)\n",
    "plt.tight_layout()\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "time_execution_difference = stop_time - start_time\n",
    "print(\"Execution time was:\", time_execution_difference, \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment: detect people all by once and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start measuring execution time\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "## initialize KP detector\n",
    "predictor_kp, cfg_kp = __init__(mode=\"KP\")\n",
    "\n",
    "## make predictions\n",
    "predictions_kp = performDetection(predictor=predictor_kp, image=image, classReduction=False)\n",
    "\n",
    "## make visualization part\n",
    "viz_kp = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "viz_kp_dots = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_od.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "output_kp_dots = viz_kp_dots.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "image_final = output_kp.get_image()[:, :, ::-1]\n",
    "image_final_dots = output_kp_dots.get_image()[:, :, ::-1]\n",
    "\n",
    "## show resulsts\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 16))\n",
    "ax[0].imshow(image_final)\n",
    "ax[1].imshow(image_final_dots)\n",
    "plt.tight_layout()\n",
    "\n",
    "## stop measuring execution time\n",
    "stop_time = timeit.default_timer()\n",
    "time_execution_difference = stop_time - start_time\n",
    "print(\"Execution time was:\", time_execution_difference, \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. people classification:\n",
    "- ## entering the road\n",
    "- ## being on the road\n",
    "- ## off the interest scope (on a bike, motorcycle, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add picture skeleton data to dataframe for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPedestrianDataToDataFrame(predictions, index, classification, df=None):\n",
    "    \"\"\"\n",
    "    Method resonsible for creating DataFrame from predictions' keypoints\n",
    "\n",
    "    :param: predictions: predictions for the whole scene\n",
    "    :param: index: index of the selected person\n",
    "    :param: classification: label for the new entry ('stationary', 'in motion')\n",
    "    :param: df: pandas DataFrame\n",
    "\n",
    "    return existing df with appended new entry if df is not None and df with new entry only otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    keypoints_x = predictions[\"instances\"][index].pred_keypoints.to(\"cpu\").numpy()[:,:,0]\n",
    "    keypoints_x_normalized = keypoints_x / np.linalg.norm(keypoints_x)\n",
    "    keypoints_y = predictions[\"instances\"][index].pred_keypoints.to(\"cpu\").numpy()[:,:,1]\n",
    "    keypoints_y_normalized = keypoints_y / np.linalg.norm(keypoints_y)\n",
    "    # keypoints_score = predictions[\"instances\"][index].pred_keypoints.to(\"cpu\").numpy()[:,:,2]\n",
    "\n",
    "    # keypoint_vector = np.hstack([keypoints_x_normalized, keypoints_y_normalized, keypoints_score])\n",
    "    keypoint_vector = np.hstack([keypoints_x_normalized, keypoints_y_normalized])\n",
    "\n",
    "    df_new = pd.DataFrame(keypoint_vector)\n",
    "    df_new['classification'] = classification\n",
    "    if df is not None:\n",
    "        df = df.append(df_new)\n",
    "        return df\n",
    "    else:\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method responsible for deploying SVM One vs Other strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyOneVsOther(df_classification, df_skeleton, model, movement, vector):\n",
    "    \"\"\"\n",
    "    Method resonsible for deploying SVM One vs Other strategy on given data\n",
    "\n",
    "    :param: df_classification: DataFrame with classification data\n",
    "    :param: df_skeleton: DataFrame with skeleton data\n",
    "    :param: model: SVM model instance\n",
    "    :param: movement: investigated movement i.e. go-left\n",
    "    :param: vector: keypoints for intvestigated person\n",
    "\n",
    "    return movement if classified and 'other' if not\n",
    "    \"\"\"\n",
    "\n",
    "    df_classification['simplified_classification'] = np.where(df_classification['classification'] == movement, 1, -1)\n",
    "    Y = np.array(df_classification['simplified_classification'])\n",
    "    X = np.array(df_skeleton)\n",
    "    model.performFit(X,Y)\n",
    "    y_hat = model.makePrediction(vector)\n",
    "    if y_hat == 1:\n",
    "        return movement\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metohod responsible for classifying person's movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPerson(df_classification, df_skeleton, model, vector):\n",
    "    \"\"\"\n",
    "    Method resonsible for classifying person movement i.e. ['go-left', 'go-forward']\n",
    "\n",
    "    :param: df_classification: DataFrame with classification data\n",
    "    :param: df_skeleton: DataFrame with skeleton data\n",
    "    :param: model: SVM model instance\n",
    "    :param: vector: keypoints for intvestigated person\n",
    "\n",
    "    return person's classification\n",
    "    \"\"\"\n",
    "\n",
    "    classificationFinal = []\n",
    "    for option in ['stationary', 'go-left', 'go-right', 'go-forward', 'go-backward']:\n",
    "        classificationPartial = classifyOneVsOther(df_classification, df_skeleton, model, option, vector)\n",
    "        if classificationPartial != \"other\":\n",
    "            classificationFinal.append(classificationPartial)\n",
    "    return classificationFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read skeleton data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "# df_skeleton = df_skeleton.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "# df_classification = df_classification.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize SVM model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "max_iter = 1000\n",
    "epsilon = 0.0001\n",
    "kernel_type = 'linear'\n",
    "\n",
    "model = SVM(max_iter,kernel_type,C,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = addPedestrianDataToDataFrame(predictions=predictions_kp, index=0, classification=\"in motion\")\n",
    "vector = np.array(df)[0][:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = classifyPerson(df_classification, df_skeleton, model, vector)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# prepare detectors\n",
    "## initialize OD detector\n",
    "predictor_od, cfg_od = __init__(mode=\"OD\")\n",
    "\n",
    "## initialize KP detector\n",
    "predictor_kp, cfg_kp = __init__(mode=\"KP\")\n",
    "\n",
    "# 0. load an image\n",
    "imagePath = \"images/cross_walk_she.png\"\n",
    "image = loadImage(imagePath=imagePath, changeColorMode=True)\n",
    "\n",
    "# 1. perform detection and make prediction boxes\n",
    "(\n",
    "    predictions_od,\n",
    "    reduced_predictions_od,\n",
    "    prediction_od_boxes,\n",
    ") = performDetection(\n",
    "    predictor=predictor_od, image=image, classReduction=True\n",
    ")\n",
    "## make visualization part\n",
    "viz_od = Visualizer(\n",
    "    image[:, :, ::-1],\n",
    "    metadata=MetadataCatalog.get(cfg_od.DATASETS.TRAIN[0]),\n",
    "    instance_mode=ColorMode.IMAGE,\n",
    ")\n",
    "output_od = viz_od.draw_instance_predictions(reduced_predictions_od.to(\"cpu\"))\n",
    "image_with_boxes = output_od.get_image()[:, :, ::-1]\n",
    "\n",
    "number_of_people = len(reduced_predictions_od)\n",
    "predictions_kp_all = {}\n",
    "images_kp_all = {}\n",
    "image_final = image.copy()\n",
    "\n",
    "for person_index in range(number_of_people):\n",
    "    # 2. cut part of the image from bounding boxes\n",
    "    image_cropped, cropped_image_coordinates = cropImageByBoundingBox(\n",
    "        image=image, box=prediction_od_boxes[person_index]\n",
    "    )\n",
    "\n",
    "    # 3. make individual skeletonization for the cropped image\n",
    "    ## perform detection\n",
    "    predictions_kp = performDetection(\n",
    "        predictor=predictor_kp, image=image_cropped, classReduction=False\n",
    "    )\n",
    "    ## make visualization part\n",
    "    viz_kp = Visualizer(\n",
    "        image_cropped[:, :, ::-1],\n",
    "        metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]),\n",
    "        instance_mode=ColorMode.IMAGE,\n",
    "    )\n",
    "    index = chooseIndexOfBestKeypointInstanceFromAllDetected(predictions=predictions_kp)\n",
    "    if index == 0:\n",
    "        output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "    else:\n",
    "        output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"][index].to(\"cpu\"))\n",
    "    image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "\n",
    "    # 4. project individual mask on the initial picture\n",
    "    corrected_predictions = correctIndividualSkeletonCoordinates(\n",
    "        initialPredictions=predictions_kp,\n",
    "        image=image_cropped,\n",
    "        croppedImageCoordinates=cropped_image_coordinates,\n",
    "    )\n",
    "    ## make visualization part\n",
    "    viz_kp = Visualizer(\n",
    "        image[:, :, ::-1],\n",
    "        metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]),\n",
    "        instance_mode=ColorMode.IMAGE,\n",
    "    )\n",
    "    if index == 0:\n",
    "        output_kp = viz_kp.draw_instance_predictions(corrected_predictions.to(\"cpu\"))\n",
    "    else:\n",
    "        output_kp = viz_kp.draw_instance_predictions(corrected_predictions[index].to(\"cpu\"))\n",
    "    image_skeletonized = output_kp.get_image()[:, :, ::-1]\n",
    "    ## combine all results\n",
    "    if index == 0:\n",
    "      predictions_kp_all[person_index] = corrected_predictions.to(\"cpu\")\n",
    "    else:\n",
    "      predictions_kp_all[person_index] = corrected_predictions[index].to(\"cpu\")\n",
    "\n",
    "    images_kp_all[person_index] = image_skeletonized\n",
    "\n",
    "final_predictions = combineAllPredictionsTogether(predictionsDict=predictions_kp_all)\n",
    "viz_kp = Visualizer(\n",
    "        image[:, :, ::-1],\n",
    "        metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]),\n",
    "        instance_mode=ColorMode.IMAGE,\n",
    ")\n",
    "output_sum = viz_kp.draw_instance_predictions(final_predictions.to(\"cpu\"))\n",
    "image_sum = output_sum.get_image()[:, :, ::-1]\n",
    "\n",
    "# 5. classify pedestrians\n",
    "## import skeleton and classification data\n",
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()\n",
    "\n",
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "\n",
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "\n",
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]\n",
    "\n",
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "\n",
    "## initialize SVM model\n",
    "C = 1\n",
    "max_iter = 1000\n",
    "epsilon = 0.0001\n",
    "kernel_type = 'linear'\n",
    "model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "\n",
    "## perform person classification\n",
    "for person_index in range(number_of_people):\n",
    "    df = addPedestrianDataToDataFrame(predictions=predictions_kp, index=0, classification=\"in motion\")\n",
    "    vector = np.array(df)[0][:34]\n",
    "\n",
    "    person_classification = classifyPerson(df_classification, df_skeleton, model, vector)\n",
    "    print(\"Person \", person_index, ': ', person_classification)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image_sum)\n",
    "plt.tight_layout()\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "time_execution_difference = stop_time - start_time\n",
    "print(\"Execution time was:\", time_execution_difference, \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment: detect people all by once, classify them and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start measuring execution time\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "## initialize KP detector\n",
    "predictor_kp, cfg_kp = __init__(mode=\"KP\")\n",
    "\n",
    "## make predictions\n",
    "predictions_kp = performDetection(predictor=predictor_kp, image=image, classReduction=False)\n",
    "\n",
    "## make visualization part\n",
    "viz_kp = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_kp.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "viz_kp_dots = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg_od.DATASETS.TRAIN[0]), instance_mode=ColorMode.IMAGE)\n",
    "output_kp = viz_kp.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "output_kp_dots = viz_kp_dots.draw_instance_predictions(predictions_kp[\"instances\"].to(\"cpu\"))\n",
    "image_final = output_kp.get_image()[:, :, ::-1]\n",
    "image_final_dots = output_kp_dots.get_image()[:, :, ::-1]\n",
    "\n",
    "# 5. classify pedestrians\n",
    "## import skeleton and classification data\n",
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()\n",
    "\n",
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "\n",
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "\n",
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]\n",
    "\n",
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "\n",
    "## initialize SVM model\n",
    "C = 1\n",
    "max_iter = 1000\n",
    "epsilon = 0.0001\n",
    "kernel_type = 'linear'\n",
    "model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "\n",
    "## perform person classification\n",
    "number_of_people = len(predictions_kp[\"instances\"])\n",
    "for person_index in range(number_of_people):\n",
    "    df = addPedestrianDataToDataFrame(predictions=predictions_kp, index=0, classification=\"in motion\")\n",
    "    vector = np.array(df)[0][:34]\n",
    "\n",
    "    person_classification = classifyPerson(df_classification, df_skeleton, model, vector)\n",
    "    print(\"Person \", person_index, ': ', person_classification)\n",
    "\n",
    "## show resulsts\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 16))\n",
    "ax[0].imshow(image_final)\n",
    "ax[1].imshow(image_final_dots)\n",
    "plt.tight_layout()\n",
    "\n",
    "## stop measuring execution time\n",
    "stop_time = timeit.default_timer()\n",
    "time_execution_difference = stop_time - start_time\n",
    "print(\"Execution time was:\", time_execution_difference, \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. calculate SVM statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate, False Negative Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more info: https://github.com/sepandhaghighi/pycm\n",
    "from pycm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()\n",
    "\n",
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "\n",
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "\n",
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]\n",
    "\n",
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for --- Stationary (1) or In-motion (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification['simplified_classification'] = np.where(df_classification['classification'] == 'stationary', 1, -1)\n",
    "y_actual = np.array(df_classification['simplified_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncut = int(len(y_actual)*0.8)\n",
    "\n",
    "y_actual_train = y_actual[:ncut]\n",
    "y_actual_test = y_actual[ncut:]\n",
    "\n",
    "x_train = df_skeleton[:ncut]\n",
    "x_test = df_skeleton[ncut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "max_iter = 1000\n",
    "epsilon = 0.0001\n",
    "kernel_type = 'linear'\n",
    "model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "\n",
    "X = np.array(x_train)\n",
    "Y = np.array(y_actual_train)\n",
    "\n",
    "model.performFit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for _, row in x_test.iterrows():\n",
    "    vector = np.array([])\n",
    "    for col_name in new_column_names:\n",
    "        skeleton_value = row[col_name]\n",
    "        vector = np.append(vector, skeleton_value)\n",
    "    person_classification = int(model.makePrediction(vector))\n",
    "    y_pred.append(person_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['ACC'\n",
    "                    ,'AGF'\n",
    "                    ,'AGM'\n",
    "                    ,'AUC'\n",
    "                    ,'AUPR'\n",
    "                    ,'BCD'\n",
    "                    ,'BM'\n",
    "                    ,'CEN'\n",
    "                    ,'ERR'\n",
    "                    ,'F0.5'\n",
    "                    ,'F1'\n",
    "                    ,'F2'\n",
    "                    ,'FDR'\n",
    "                    ,'FN'\n",
    "                    ,'FNR'\n",
    "                    ,'FOR'\n",
    "                    ,'FP'\n",
    "                    ,'FPR'\n",
    "                    ,'G'\n",
    "                    ,'GI'\n",
    "                    ,'GM'\n",
    "                    ,'IBA'\n",
    "                    ,'ICSI'\n",
    "                    ,'IS'\n",
    "                    ,'J'\n",
    "                    ,'LS'\n",
    "                    ,'MCEN'\n",
    "                    ,'N'\n",
    "                    ,'NLR'\n",
    "                    ,'NPV'\n",
    "                    ,'OC'\n",
    "                    ,'OOC'\n",
    "                    ,'OP'\n",
    "                    ,'P'\n",
    "                    ,'PLR'\n",
    "                    ,'POP'\n",
    "                    ,'PPV'\n",
    "                    ,'PRE'\n",
    "                    ,'RACC'\n",
    "                    ,'RACCU'\n",
    "                    ,'TN'\n",
    "                    ,'TNR'\n",
    "                    ,'TON'\n",
    "                    ,'TOP'\n",
    "                    ,'TP'\n",
    "                    ,'TPR'\n",
    "                    ,'Y'\n",
    "                    ,'dInd'\n",
    "                    ,'sInd']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"c\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for c in np.arange(0.2, 1.9, 0.1):\n",
    "    C = c\n",
    "    max_iter = 1000\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"c\": c, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.copy()\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"c\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for c in np.arange(0.2, 1.9, 0.1):\n",
    "    C = c\n",
    "    max_iter = 1000\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'quadratic'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"c\": c, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2= df.copy()\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_1.plot()\n",
    "df_2.plot(ax=ax)\n",
    "ax.set_xticks(np.arange(0.2, 1.9, 0.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Max iter\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [100, 1000, 10000]:\n",
    "    C = 1\n",
    "    max_iter = mi\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Max iter\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Max iter\")\n",
    "\n",
    "df_3 = df.copy()\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Max iter\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [100, 1000, 10000]:\n",
    "    C = 1\n",
    "    max_iter = mi\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'quadratic'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Max iter\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Max iter\")\n",
    "\n",
    "df_4 = df.copy()\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_3.plot()\n",
    "df_4.plot(ax=ax)\n",
    "ax.set_xticks([100, 1000, 10000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Epsilon\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [0.1, 0.01, 0.001, 0.0001, 0.0001, 0.00001, 0.00001]:\n",
    "    C = 1\n",
    "    max_iter = 1000\n",
    "    epsilon = mi\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Epsilon\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Epsilon\")\n",
    "\n",
    "df_5 = df.copy()\n",
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Epsilon\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [0.1, 0.01, 0.001, 0.0001, 0.0001, 0.00001, 0.00001]:\n",
    "    C = 1\n",
    "    max_iter = 1000\n",
    "    epsilon = mi\n",
    "    kernel_type = 'quadratic'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Epsilon\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Epsilon\")\n",
    "\n",
    "df_5 = df.copy()\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for --- Stationary (0), Go-forward (1), Go-right (2), Go-backward (3), Go-left (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification['simplified_classification'] = np.where(df_classification['classification'] == 'stationary', 0,\\\n",
    "    np.where(df_classification['classification'] == 'go-forward', 1,\\\n",
    "    np.where(df_classification['classification'] == 'go-right', 2,\\\n",
    "    np.where(df_classification['classification'] == 'go-backward', 3,\\\n",
    "    np.where(df_classification['classification'] == 'go-left', 4, np.nan)))))\n",
    "\n",
    "y_actual = np.array(df_classification['simplified_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncut = int(len(y_actual)*0.8)\n",
    "\n",
    "y_actual_train = y_actual[:ncut]\n",
    "y_actual_test = y_actual[ncut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "max_iter = 1000\n",
    "epsilon = 0.0001\n",
    "kernel_type = 'linear'\n",
    "model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "\n",
    "personClassification = classifyPerson(df_classification, df_skeleton, model, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = ['go-backward', 'go-left', 'go-forward', 'go-right']\n",
    "def simplifyClassification(classification):\n",
    "    if 'go-left' in classification and 'go-right' not in classification:\n",
    "        print('go-left')\n",
    "        return 4.0\n",
    "    elif 'go-left' not in classification and 'go-right' in classification:\n",
    "        print('go-right')\n",
    "        return 2.0\n",
    "    elif 'go-forward' in classification and 'go-backward' not in classification:\n",
    "        print('go-forward')\n",
    "        return 1.0\n",
    "    elif 'go-forward' not in classification and 'go-backward' in classification:\n",
    "        print('go-backward')\n",
    "        return 3.0\n",
    "    else:\n",
    "        print('stationary')\n",
    "        return 0.0\n",
    "simplifyClassification(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for _, row in x_test.iterrows():\n",
    "    start_time = timeit.default_timer()\n",
    "    vector = np.array([])\n",
    "    for col_name in new_column_names:\n",
    "        skeleton_value = row[col_name]\n",
    "        vector = np.append(vector, skeleton_value)\n",
    "    person_classification = simplifyClassification(classifyPerson(df_classification, df_skeleton, model, vector))\n",
    "    y_pred.append(person_classification)\n",
    "    stop_time = timeit.default_timer()\n",
    "    time_execution_difference = stop_time - start_time\n",
    "    print(\"Execution time was:\", time_execution_difference, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_actual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0.0': 'Stationary', '1.0': 'Go-forward', '2.0': 'Go-right', '3.0': 'Go-backward', '4.0': 'Go-left'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['ACC'\n",
    "                    ,'AGF'\n",
    "                    ,'AGM'\n",
    "                    ,'AUC'\n",
    "                    ,'AUPR'\n",
    "                    ,'BCD'\n",
    "                    ,'BM'\n",
    "                    ,'CEN'\n",
    "                    ,'ERR'\n",
    "                    ,'F0.5'\n",
    "                    ,'F1'\n",
    "                    ,'F2'\n",
    "                    ,'FDR'\n",
    "                    ,'FN'\n",
    "                    ,'FNR'\n",
    "                    ,'FOR'\n",
    "                    ,'FP'\n",
    "                    ,'FPR'\n",
    "                    ,'G'\n",
    "                    ,'GI'\n",
    "                    ,'GM'\n",
    "                    ,'IBA'\n",
    "                    ,'ICSI'\n",
    "                    ,'IS'\n",
    "                    ,'J'\n",
    "                    ,'LS'\n",
    "                    ,'MCEN'\n",
    "                    ,'N'\n",
    "                    ,'NLR'\n",
    "                    ,'NPV'\n",
    "                    ,'OC'\n",
    "                    ,'OOC'\n",
    "                    ,'OP'\n",
    "                    ,'P'\n",
    "                    ,'PLR'\n",
    "                    ,'POP'\n",
    "                    ,'PPV'\n",
    "                    ,'PRE'\n",
    "                    ,'RACC'\n",
    "                    ,'RACCU'\n",
    "                    ,'TN'\n",
    "                    ,'TNR'\n",
    "                    ,'TON'\n",
    "                    ,'TOP'\n",
    "                    ,'TP'\n",
    "                    ,'TPR'\n",
    "                    ,'Y'\n",
    "                    ,'dInd'\n",
    "                    ,'sInd']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"c\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for c in np.arange(0.2, 1.9, 0.1):\n",
    "    C = c\n",
    "    max_iter = 1000\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"c\": c, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.copy()\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"c\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for c in np.arange(0.2, 1.9, 0.1):\n",
    "    C = c\n",
    "    max_iter = 1000\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'quadratic'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"c\": c, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2= df.copy()\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_1.plot()\n",
    "df_2.plot(ax=ax)\n",
    "ax.set_xticks(np.arange(0.2, 1.9, 0.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Max iter\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [100, 1000, 10000]:\n",
    "    C = 1\n",
    "    max_iter = mi\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Max iter\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Max iter\")\n",
    "\n",
    "df_3 = df.copy()\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Max iter\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [100, 1000, 10000]:\n",
    "    C = 1\n",
    "    max_iter = mi\n",
    "    epsilon = 0.0001\n",
    "    kernel_type = 'quadratic'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Max iter\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Max iter\")\n",
    "\n",
    "df_4 = df.copy()\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_3.plot()\n",
    "df_4.plot(ax=ax)\n",
    "ax.set_xticks([100, 1000, 10000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Epsilon\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [0.1, 0.01, 0.001, 0.0001, 0.0001, 0.00001, 0.00001]:\n",
    "    C = 1\n",
    "    max_iter = 1000\n",
    "    epsilon = mi\n",
    "    kernel_type = 'linear'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Epsilon\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Epsilon\")\n",
    "\n",
    "df_5 = df.copy()\n",
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Epsilon\", \"Stationary FP\", \"Stationary FN\", \"In-motion FP\", \"In-motion FN\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for mi in [0.1, 0.01, 0.001, 0.0001, 0.0001, 0.00001, 0.00001]:\n",
    "    C = 1\n",
    "    max_iter = 1000\n",
    "    epsilon = mi\n",
    "    kernel_type = 'quadratic'\n",
    "\n",
    "    stationary_fp = np.array([])\n",
    "    stationary_fn = np.array([])\n",
    "    in_motion_fp = np.array([])\n",
    "    in_motion_fn = np.array([])\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        model = SVM(max_iter,kernel_type,C,epsilon)\n",
    "        X = np.array(x_train)\n",
    "        Y = np.array(y_actual_train)\n",
    "        model.performFit(X,Y)\n",
    "        y_pred = []\n",
    "        for _, row in x_test.iterrows():\n",
    "            vector = np.array([])\n",
    "            for col_name in new_column_names:\n",
    "                skeleton_value = row[col_name]\n",
    "                vector = np.append(vector, skeleton_value)\n",
    "            person_classification = int(model.makePrediction(vector))\n",
    "            y_pred.append(person_classification)\n",
    "        cm = ConfusionMatrix(actual_vector=y_actual_test, predict_vector=y_pred)\n",
    "        name = \"cm_experiment\"\n",
    "        cm.save_csv(name=name)\n",
    "        name += \".csv\"\n",
    "        cm_stats = pd.read_csv(name, index_col='Class')\n",
    "        cm_stats = cm_stats.rename(columns={'-1': 'In-motion', '1': 'Stationary'})\n",
    "        cm_stats_IN_MOTION = cm_stats['In-motion']\n",
    "        cm_stats_STATIONARY = cm_stats['Stationary']\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats = cm_stats[['FP', 'FN']]\n",
    "        cm_stats = cm_stats.T\n",
    "        cm_stats\n",
    "\n",
    "        stationary_fp = np.append(stationary_fp, int(cm_stats.loc['FP']['Stationary']))\n",
    "        stationary_fn = np.append(stationary_fn, int(cm_stats.loc['FN']['Stationary']))\n",
    "        in_motion_fp = np.append(in_motion_fp, int(cm_stats.loc['FP']['In-motion']))\n",
    "        in_motion_fn = np.append(in_motion_fn, int(cm_stats.loc['FN']['In-motion']))\n",
    "\n",
    "    # print('\\nc:', c)\n",
    "    # print(\"\\n\\t['FP']['Stationary']:\", stationary_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['Stationary']:\", stationary_fn.mean())\n",
    "    # print(\"\\n\\t['FP']['In-motion']:\", in_motion_fp.mean())\n",
    "    # print(\"\\n\\t['FN']['In-motion']:\", in_motion_fn.mean())\n",
    "\n",
    "    dict = {\"Epsilon\": mi, \"Stationary FP\": stationary_fp.mean(), \"Stationary FN\": stationary_fn.mean(), \"In-motion FP\": in_motion_fp.mean(), \"In-motion FN\": in_motion_fn.mean()}\n",
    "    df = df.append(dict, ignore_index = True)\n",
    "\n",
    "df = df.set_index(\"Epsilon\")\n",
    "\n",
    "df_5 = df.copy()\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on: https://github.com/lschmiddey/PyTorch-Multiclass-Classification/blob/master/Multiclass_Classification_on_Iris_dataset_with_Initialization_and_Dropout.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michal/opt/anaconda3/envs/detectron2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pycm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()\n",
    "\n",
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "\n",
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "\n",
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]\n",
    "\n",
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "\n",
    "df_classification['simplified_classification'] = np.where(df_classification['classification'] == 'stationary', 0,\\\n",
    "    np.where(df_classification['classification'] == 'go-forward', 1,\\\n",
    "    np.where(df_classification['classification'] == 'go-right', 2,\\\n",
    "    np.where(df_classification['classification'] == 'go-backward', 3,\\\n",
    "    np.where(df_classification['classification'] == 'go-left', 4, np.nan)))))\n",
    "\n",
    "y_actual = np.array(df_classification['simplified_classification'])\n",
    "\n",
    "ncut = int(len(y_actual)*0.8)\n",
    "\n",
    "y = y_actual[:ncut]\n",
    "y_val = y_actual[ncut:]\n",
    "\n",
    "x = np.array(df_skeleton[:ncut])\n",
    "x_val = np.array(df_skeleton[ncut:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val\n",
    "\n",
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x).type(torch.FloatTensor)\n",
    "        self.y=torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=Data()\n",
    "trainloader=DataLoader(dataset=data_set,batch_size=10)\n",
    "data_set.x.shape, data_set.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,in_size,n_hidden1,n_hidden2,out_size,p=0):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        self.drop=nn.Dropout(p=p)\n",
    "        self.linear1=nn.Linear(in_size,n_hidden1)\n",
    "        # nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear2=nn.Linear(n_hidden1,n_hidden2)\n",
    "        # nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear3=nn.Linear(n_hidden2,n_hidden2)\n",
    "        # nn.init.kaiming_uniform_(self.linear3.weight,nonlinearity='relu')\n",
    "        self.linear4=nn.Linear(n_hidden2,out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.linear1(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear2(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear3(x))\n",
    "        x=self.drop(x)\n",
    "        x=self.linear4(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(34, 68, 34, 5)\n",
    "model_drop=Net(34, 68, 34, 5, p=0.2)\n",
    "model_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ofit = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer_drop = torch.optim.Adam(model_drop.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS={}\n",
    "LOSS['training data no dropout']=[]\n",
    "LOSS['validation data no dropout']=[]\n",
    "LOSS['training data dropout']=[]\n",
    "LOSS['validation data dropout']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model = model.float()\n",
    "    model_drop = model_drop.float()\n",
    "    for x, y in trainloader:\n",
    "        #make a prediction for both models\n",
    "        yhat = model(data_set.x)\n",
    "        yhat_drop = model_drop(data_set.x)\n",
    "        #calculate the lossf or both models\n",
    "        loss = criterion(yhat, data_set.y)\n",
    "        loss_drop = criterion(yhat_drop, data_set.y)\n",
    "\n",
    "        #store the loss for  both the training and validation  data for both models\n",
    "        LOSS['training data no dropout'].append(loss.item())\n",
    "        LOSS['training data dropout'].append(loss_drop.item())\n",
    "        model_drop.eval()\n",
    "        model_drop.train()\n",
    "\n",
    "        #clear gradient\n",
    "        optimizer_ofit.zero_grad()\n",
    "        optimizer_drop.zero_grad()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        loss_drop.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer_ofit.step()\n",
    "        optimizer_drop.step()\n",
    "\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(yhat.data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model(x_val)\n",
    "z_dropout = model_drop(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yhat=torch.max(z.data,1)\n",
    "yhat[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yhat_dropout=torch.max(z_dropout.data,1)\n",
    "yhat_dropout[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "eval_matrix = (pd.crosstab(y_val, yhat))\n",
    "print(eval_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "eval_matrix_dropout = (pd.crosstab(y_val, yhat_dropout))\n",
    "print(eval_matrix_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_matrix[0][0]+eval_matrix[1][1]+eval_matrix[2][2])/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_matrix_dropout[0][0]+eval_matrix_dropout[1][1]+eval_matrix_dropout[2][2])/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = addPedestrianDataToDataFrame(predictions=predictions_kp, index=1, classification=\"in motion\")\n",
    "vector = np.array(np.array(df)[0][:34], dtype=np.float64)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_1 = torch.from_numpy(np.array([list(vector)]))\n",
    "vector_1 = torch.from_numpy(vector)\n",
    "vector_1 = vector_1.double()\n",
    "vector_1 = vector_1.view(-1, len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(vector_1.float())\n",
    "prob = torch.mul(F.softmax(output, dim=1), 100)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.argmax(prob.detach().numpy())\n",
    "best_index_probability = np.max(prob.detach().numpy())\n",
    "\n",
    "print(\"best index:\", best_index, \", probability:\", round(best_index_probability, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(prob.detach().numpy()) # probability should sum up to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['FP', 'FN']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# tb = SummaryWriter()\n",
    "tb = SummaryWriter('/Users/michal/Documents/Study/MSc/Diploma project/Codes/my_model/logsdir')\n",
    "inputs, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(inputs)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, x)\n",
    "tb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 layer feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()\n",
    "\n",
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "\n",
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "\n",
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]\n",
    "\n",
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "\n",
    "df_classification['simplified_classification'] = np.where(df_classification['classification'] == 'stationary', 0,\\\n",
    "    np.where(df_classification['classification'] == 'go-forward', 1,\\\n",
    "    np.where(df_classification['classification'] == 'go-right', 2,\\\n",
    "    np.where(df_classification['classification'] == 'go-backward', 3,\\\n",
    "    np.where(df_classification['classification'] == 'go-left', 4, np.nan)))))\n",
    "\n",
    "y_actual = np.array(df_classification['simplified_classification'])\n",
    "\n",
    "ncut = int(len(y_actual)*0.8)\n",
    "\n",
    "y = y_actual[:ncut]\n",
    "y_val = y_actual[ncut:]\n",
    "\n",
    "x = np.array(df_skeleton[:ncut])\n",
    "x_val = np.array(df_skeleton[ncut:])\n",
    "\n",
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val\n",
    "\n",
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x).type(torch.FloatTensor)\n",
    "        self.y=torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_set=Data()\n",
    "trainloader=DataLoader(dataset=data_set,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,in_size,n_hidden1,n_hidden2,out_size,p=0):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        self.drop=nn.Dropout(p=p)\n",
    "        self.linear1=nn.Linear(in_size,n_hidden1)\n",
    "        # nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear2=nn.Linear(n_hidden1,n_hidden2)\n",
    "        # nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear3=nn.Linear(n_hidden2,out_size)\n",
    "        # nn.init.kaiming_uniform_(self.linear3.weight,nonlinearity='relu')\n",
    "        # self.linear4=nn.Linear(n_hidden2,out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.linear1(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear2(x))\n",
    "        x=self.drop(x)\n",
    "        # x=F.relu(self.linear3(x))\n",
    "        # x=self.drop(x)\n",
    "        x=self.linear3(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Net(34, 68, 68, 5)\n",
    "model_drop = Net(34, 68, 68, 5, p=0.2)\n",
    "\n",
    "optimizer_ofit = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer_drop = torch.optim.Adam(model_drop.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "LOSS={}\n",
    "LOSS['training data no dropout']=[]\n",
    "LOSS['validation data no dropout']=[]\n",
    "LOSS['training data dropout']=[]\n",
    "LOSS['validation data dropout']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss 1.5024714223922244\n",
      "epoch 1, train loss 1.4691078284430126\n",
      "epoch 2, train loss 1.1225784231746008\n",
      "epoch 2, train loss 1.0972377307831296\n",
      "epoch 3, train loss 0.8517626192834642\n",
      "epoch 3, train loss 0.8940683811429947\n",
      "epoch 4, train loss 0.7744827156975156\n",
      "epoch 4, train loss 0.8197936122379605\n",
      "epoch 5, train loss 0.7326533548415654\n",
      "epoch 5, train loss 0.7837984183477977\n",
      "epoch 6, train loss 0.6968518722625006\n",
      "epoch 6, train loss 0.757282745270502\n",
      "epoch 7, train loss 0.6573349000915648\n",
      "epoch 7, train loss 0.7366400077229455\n",
      "epoch 8, train loss 0.6150856831717113\n",
      "epoch 8, train loss 0.7161346446900141\n",
      "epoch 9, train loss 0.5654981580991594\n",
      "epoch 9, train loss 0.6979639142278641\n",
      "epoch 10, train loss 0.5111868830900343\n",
      "epoch 10, train loss 0.6752010725793385\n",
      "epoch 11, train loss 0.4655118736009749\n",
      "epoch 11, train loss 0.6430813906684755\n",
      "epoch 12, train loss 0.4316109012043665\n",
      "epoch 12, train loss 0.6182512622030955\n",
      "epoch 13, train loss 0.4056492012644571\n",
      "epoch 13, train loss 0.595497863633292\n",
      "epoch 14, train loss 0.38528031583816286\n",
      "epoch 14, train loss 0.5725733836491903\n",
      "epoch 15, train loss 0.36798707691449967\n",
      "epoch 15, train loss 0.5541545871704344\n",
      "epoch 16, train loss 0.3528518719332559\n",
      "epoch 16, train loss 0.5386439930825007\n",
      "epoch 17, train loss 0.3392217012624892\n",
      "epoch 17, train loss 0.5249814873649961\n",
      "epoch 18, train loss 0.32663103890797446\n",
      "epoch 18, train loss 0.5114787414906516\n",
      "epoch 19, train loss 0.31552313244532026\n",
      "epoch 19, train loss 0.49665727170686874\n",
      "epoch 20, train loss 0.3051801550955999\n",
      "epoch 20, train loss 0.4820854886183663\n",
      "epoch 21, train loss 0.2954182880265372\n",
      "epoch 21, train loss 0.4689503406721448\n",
      "epoch 22, train loss 0.2862646669622452\n",
      "epoch 22, train loss 0.4580591642667377\n",
      "epoch 23, train loss 0.277605932856363\n",
      "epoch 23, train loss 0.44605798002273317\n",
      "epoch 24, train loss 0.2690463856099144\n",
      "epoch 24, train loss 0.43615155418713886\n",
      "epoch 25, train loss 0.26086822767106316\n",
      "epoch 25, train loss 0.4275792908100855\n",
      "epoch 26, train loss 0.2530612787083974\n",
      "epoch 26, train loss 0.41620095760103254\n",
      "epoch 27, train loss 0.24551499765070658\n",
      "epoch 27, train loss 0.4078698257605235\n",
      "epoch 28, train loss 0.23836398952537113\n",
      "epoch 28, train loss 0.3955335697484395\n",
      "epoch 29, train loss 0.23127806328591846\n",
      "epoch 29, train loss 0.388673638540601\n",
      "epoch 30, train loss 0.22455965479214987\n",
      "epoch 30, train loss 0.37646067284402396\n",
      "epoch 31, train loss 0.21776243902388073\n",
      "epoch 31, train loss 0.3718214711499593\n",
      "epoch 32, train loss 0.21133575150890957\n",
      "epoch 32, train loss 0.3628895580768585\n",
      "epoch 33, train loss 0.2048157202819037\n",
      "epoch 33, train loss 0.35733524343324086\n",
      "epoch 34, train loss 0.19763058565911792\n",
      "epoch 34, train loss 0.35166378484831917\n",
      "epoch 35, train loss 0.19071818320524125\n",
      "epoch 35, train loss 0.3427880169853332\n",
      "epoch 36, train loss 0.1840238223473231\n",
      "epoch 36, train loss 0.3349454246816181\n",
      "epoch 37, train loss 0.17769233953385127\n",
      "epoch 37, train loss 0.3278083214684138\n",
      "epoch 38, train loss 0.17131729755136701\n",
      "epoch 38, train loss 0.3216353900848873\n",
      "epoch 39, train loss 0.1651976283580538\n",
      "epoch 39, train loss 0.31932836061432246\n",
      "epoch 40, train loss 0.15913192667658366\n",
      "epoch 40, train loss 0.3123672448453449\n",
      "epoch 41, train loss 0.15312528089871483\n",
      "epoch 41, train loss 0.30402936112313045\n",
      "epoch 42, train loss 0.14697464283496614\n",
      "epoch 42, train loss 0.29902241390848916\n",
      "epoch 43, train loss 0.14151079077569265\n",
      "epoch 43, train loss 0.2936617500252194\n",
      "epoch 44, train loss 0.13592363704764654\n",
      "epoch 44, train loss 0.2891178083798242\n",
      "epoch 45, train loss 0.1306139114830229\n",
      "epoch 45, train loss 0.28049653342791964\n",
      "epoch 46, train loss 0.12532582843587511\n",
      "epoch 46, train loss 0.2778089413094142\n",
      "epoch 47, train loss 0.12042492923755495\n",
      "epoch 47, train loss 0.27409269885411336\n",
      "epoch 48, train loss 0.11561251076914016\n",
      "epoch 48, train loss 0.26807275721951135\n",
      "epoch 49, train loss 0.11084192577335569\n",
      "epoch 49, train loss 0.2684820001087492\n",
      "epoch 50, train loss 0.10619193492900758\n",
      "epoch 50, train loss 0.25833613248098464\n",
      "epoch 51, train loss 0.10181772933592872\n",
      "epoch 51, train loss 0.2541644892522267\n",
      "epoch 52, train loss 0.09735204563254402\n",
      "epoch 52, train loss 0.25267346132369267\n",
      "epoch 53, train loss 0.09331770146649981\n",
      "epoch 53, train loss 0.24530339453901565\n",
      "epoch 54, train loss 0.0896133804132068\n",
      "epoch 54, train loss 0.24261731595274003\n",
      "epoch 55, train loss 0.0856242228358511\n",
      "epoch 55, train loss 0.23485318370281705\n",
      "epoch 56, train loss 0.08214872744348314\n",
      "epoch 56, train loss 0.2330828753728715\n",
      "epoch 57, train loss 0.07868317384568471\n",
      "epoch 57, train loss 0.23045626211734044\n",
      "epoch 58, train loss 0.07535893044301442\n",
      "epoch 58, train loss 0.22480703488228812\n",
      "epoch 59, train loss 0.07226931043560543\n",
      "epoch 59, train loss 0.22577887773513794\n",
      "epoch 60, train loss 0.06905645699728102\n",
      "epoch 60, train loss 0.216307314615401\n",
      "epoch 61, train loss 0.06622291379977786\n",
      "epoch 61, train loss 0.21540239737147376\n",
      "epoch 62, train loss 0.06331965232652331\n",
      "epoch 62, train loss 0.21264609008554428\n",
      "epoch 63, train loss 0.0606783651525066\n",
      "epoch 63, train loss 0.2063200014924246\n",
      "epoch 64, train loss 0.058059384188954795\n",
      "epoch 64, train loss 0.2051926903308384\n",
      "epoch 65, train loss 0.0553240305965855\n",
      "epoch 65, train loss 0.20340403867146326\n",
      "epoch 66, train loss 0.05305570500001075\n",
      "epoch 66, train loss 0.19634259149195657\n",
      "epoch 67, train loss 0.050800985346237816\n",
      "epoch 67, train loss 0.1949354764961061\n",
      "epoch 68, train loss 0.048489501729371054\n",
      "epoch 68, train loss 0.1924058407072037\n",
      "epoch 69, train loss 0.046403915163070436\n",
      "epoch 69, train loss 0.1934238045461594\n",
      "epoch 70, train loss 0.04436193808676705\n",
      "epoch 70, train loss 0.18023230206398738\n",
      "epoch 71, train loss 0.04245457100489783\n",
      "epoch 71, train loss 0.18502731881444417\n",
      "epoch 72, train loss 0.040597253375583224\n",
      "epoch 72, train loss 0.18382345920517332\n",
      "epoch 73, train loss 0.03881456637902865\n",
      "epoch 73, train loss 0.17659657744188156\n",
      "epoch 74, train loss 0.03713350187218378\n",
      "epoch 74, train loss 0.17498863405651516\n",
      "epoch 75, train loss 0.03547253045770857\n",
      "epoch 75, train loss 0.17055792822724297\n",
      "epoch 76, train loss 0.03401639040500399\n",
      "epoch 76, train loss 0.17009552580023568\n",
      "epoch 77, train loss 0.032428035660395545\n",
      "epoch 77, train loss 0.16000417111411927\n",
      "epoch 78, train loss 0.031061297400839745\n",
      "epoch 78, train loss 0.16550214919779035\n",
      "epoch 79, train loss 0.02970914566327655\n",
      "epoch 79, train loss 0.16076333749861943\n",
      "epoch 80, train loss 0.0285864020623858\n",
      "epoch 80, train loss 0.16205845371125235\n",
      "epoch 81, train loss 0.027178905106016567\n",
      "epoch 81, train loss 0.15801829170613063\n",
      "epoch 82, train loss 0.025994473447402317\n",
      "epoch 82, train loss 0.1535789313770476\n",
      "epoch 83, train loss 0.024950671054068067\n",
      "epoch 83, train loss 0.1538530984331691\n",
      "epoch 84, train loss 0.02400091385084485\n",
      "epoch 84, train loss 0.15227823941007493\n",
      "epoch 85, train loss 0.02281274294687642\n",
      "epoch 85, train loss 0.14726013217180495\n",
      "epoch 86, train loss 0.021772056049297727\n",
      "epoch 86, train loss 0.1456578483893758\n",
      "epoch 87, train loss 0.020876865981826708\n",
      "epoch 87, train loss 0.14155012558376978\n",
      "epoch 88, train loss 0.019967371243096534\n",
      "epoch 88, train loss 0.1439144430415971\n",
      "epoch 89, train loss 0.019180421613984637\n",
      "epoch 89, train loss 0.1390976161947326\n",
      "epoch 90, train loss 0.018340777694469408\n",
      "epoch 90, train loss 0.14014761859462374\n",
      "epoch 91, train loss 0.017543559332215596\n",
      "epoch 91, train loss 0.13952308467456273\n",
      "epoch 92, train loss 0.01675970388192033\n",
      "epoch 92, train loss 0.13664939088953865\n",
      "epoch 93, train loss 0.016067670185178046\n",
      "epoch 93, train loss 0.1358871938926833\n",
      "epoch 94, train loss 0.015385516357445528\n",
      "epoch 94, train loss 0.13024660980417616\n",
      "epoch 95, train loss 0.01475888719811799\n",
      "epoch 95, train loss 0.13172601731050582\n",
      "epoch 96, train loss 0.014115124615648436\n",
      "epoch 96, train loss 0.1280892440487468\n",
      "epoch 97, train loss 0.013436662240160836\n",
      "epoch 97, train loss 0.13004920063983827\n",
      "epoch 98, train loss 0.012885420745800413\n",
      "epoch 98, train loss 0.12704702360289438\n",
      "epoch 99, train loss 0.012349346238705847\n",
      "epoch 99, train loss 0.12616940031922053\n",
      "epoch 100, train loss 0.011826886632849299\n",
      "epoch 100, train loss 0.12419804646855309\n",
      "epoch 101, train loss 0.01135390241526895\n",
      "epoch 101, train loss 0.12273972978194554\n",
      "epoch 102, train loss 0.010848726175488934\n",
      "epoch 102, train loss 0.11974986122241096\n",
      "epoch 103, train loss 0.010389215312898159\n",
      "epoch 103, train loss 0.11905259532587868\n",
      "epoch 104, train loss 0.009969778669377169\n",
      "epoch 104, train loss 0.11753961798690614\n",
      "epoch 105, train loss 0.009507746361787356\n",
      "epoch 105, train loss 0.1138215060271914\n",
      "epoch 106, train loss 0.009103438225648706\n",
      "epoch 106, train loss 0.11485987535071751\n",
      "epoch 107, train loss 0.008715237402135418\n",
      "epoch 107, train loss 0.11473291355466085\n",
      "epoch 108, train loss 0.008347949367903527\n",
      "epoch 108, train loss 0.11300022864625567\n",
      "epoch 109, train loss 0.008020990498600498\n",
      "epoch 109, train loss 0.11403011069411323\n",
      "epoch 110, train loss 0.007669388190917079\n",
      "epoch 110, train loss 0.11061630066898134\n",
      "epoch 111, train loss 0.007351916845119189\n",
      "epoch 111, train loss 0.11057146674110777\n",
      "epoch 112, train loss 0.007053088958537768\n",
      "epoch 112, train loss 0.10757047056205689\n",
      "epoch 113, train loss 0.0067624203890325535\n",
      "epoch 113, train loss 0.10648637950893432\n",
      "epoch 114, train loss 0.0065074386962112925\n",
      "epoch 114, train loss 0.10378304797978628\n",
      "epoch 115, train loss 0.006226938447013261\n",
      "epoch 115, train loss 0.10648944914814025\n",
      "epoch 116, train loss 0.0059536114142882445\n",
      "epoch 116, train loss 0.10618611153156038\n",
      "epoch 117, train loss 0.00571390978311972\n",
      "epoch 117, train loss 0.10542441798107964\n",
      "epoch 118, train loss 0.005477505174302865\n",
      "epoch 118, train loss 0.10257165453263692\n",
      "epoch 119, train loss 0.005266685253157029\n",
      "epoch 119, train loss 0.10180889472128853\n",
      "epoch 120, train loss 0.005020897946364823\n",
      "epoch 120, train loss 0.0990702940358056\n",
      "epoch 121, train loss 0.004813447239853087\n",
      "epoch 121, train loss 0.09892340643065316\n",
      "epoch 122, train loss 0.004590112124643628\n",
      "epoch 122, train loss 0.0991917492614852\n",
      "epoch 123, train loss 0.004387133067385072\n",
      "epoch 123, train loss 0.09835494108616359\n",
      "epoch 124, train loss 0.004202467005049426\n",
      "epoch 124, train loss 0.09385134752780672\n",
      "epoch 125, train loss 0.004018537434084075\n",
      "epoch 125, train loss 0.09608941572526145\n",
      "epoch 126, train loss 0.0038460748351459937\n",
      "epoch 126, train loss 0.0977523069060038\n",
      "epoch 127, train loss 0.0036874990503761975\n",
      "epoch 127, train loss 0.09774858208875807\n",
      "epoch 128, train loss 0.003531810967990803\n",
      "epoch 128, train loss 0.09483282339005243\n",
      "epoch 129, train loss 0.0033825322697382597\n",
      "epoch 129, train loss 0.09282124219905763\n",
      "epoch 130, train loss 0.0032417708083928103\n",
      "epoch 130, train loss 0.0903037940225904\n",
      "epoch 131, train loss 0.0031089844322571207\n",
      "epoch 131, train loss 0.08922664377660978\n",
      "epoch 132, train loss 0.0029873233879842455\n",
      "epoch 132, train loss 0.09326075159368061\n",
      "epoch 133, train loss 0.0028501462361346635\n",
      "epoch 133, train loss 0.08782138580840732\n",
      "epoch 134, train loss 0.002730462212292921\n",
      "epoch 134, train loss 0.08846070723874229\n",
      "epoch 135, train loss 0.002625594813642757\n",
      "epoch 135, train loss 0.08961604346358587\n",
      "epoch 136, train loss 0.0025102659239478057\n",
      "epoch 136, train loss 0.08682984113693237\n",
      "epoch 137, train loss 0.002409533771227986\n",
      "epoch 137, train loss 0.08845628460957891\n",
      "epoch 138, train loss 0.002305739803151006\n",
      "epoch 138, train loss 0.08366267891630294\n",
      "epoch 139, train loss 0.0022105882979101604\n",
      "epoch 139, train loss 0.08622589334845543\n",
      "epoch 140, train loss 0.0021179258446430878\n",
      "epoch 140, train loss 0.08672633719822717\n",
      "epoch 141, train loss 0.002031032775809604\n",
      "epoch 141, train loss 0.0883499358499807\n",
      "epoch 142, train loss 0.001947398580211614\n",
      "epoch 142, train loss 0.08615634324295181\n",
      "epoch 143, train loss 0.0018695908458164288\n",
      "epoch 143, train loss 0.08159937236517195\n",
      "epoch 144, train loss 0.0017932600559785016\n",
      "epoch 144, train loss 0.08268009321320624\n",
      "epoch 145, train loss 0.0017186484321774472\n",
      "epoch 145, train loss 0.08025079244186008\n",
      "epoch 146, train loss 0.001649695537274792\n",
      "epoch 146, train loss 0.08179156624135517\n",
      "epoch 147, train loss 0.0015813585108382599\n",
      "epoch 147, train loss 0.07890447648981261\n",
      "epoch 148, train loss 0.0015173541855007884\n",
      "epoch 148, train loss 0.08103218893446619\n",
      "epoch 149, train loss 0.0014567297831591633\n",
      "epoch 149, train loss 0.07757652261190945\n",
      "epoch 150, train loss 0.0013968202448080456\n",
      "epoch 150, train loss 0.07661159011343169\n",
      "epoch 151, train loss 0.0013403424435102986\n",
      "epoch 151, train loss 0.07577009978038925\n",
      "epoch 152, train loss 0.0012879203469122922\n",
      "epoch 152, train loss 0.07780183437797758\n",
      "epoch 153, train loss 0.0012361349645144647\n",
      "epoch 153, train loss 0.07749673747827136\n",
      "epoch 154, train loss 0.0011868922590529398\n",
      "epoch 154, train loss 0.07484164420101377\n",
      "epoch 155, train loss 0.0011391517436427493\n",
      "epoch 155, train loss 0.07805319029896979\n",
      "epoch 156, train loss 0.001095872492499886\n",
      "epoch 156, train loss 0.08228099860605739\n",
      "epoch 157, train loss 0.0010503306208799283\n",
      "epoch 157, train loss 0.07739077603060102\n",
      "epoch 158, train loss 0.0010086724475499183\n",
      "epoch 158, train loss 0.07741551976355296\n",
      "epoch 159, train loss 0.0009697272288908679\n",
      "epoch 159, train loss 0.07404780228223119\n",
      "epoch 160, train loss 0.0009317811096220144\n",
      "epoch 160, train loss 0.07190945425203868\n",
      "epoch 161, train loss 0.0008940887960812284\n",
      "epoch 161, train loss 0.07695501735286107\n",
      "epoch 162, train loss 0.0008605448870978777\n",
      "epoch 162, train loss 0.07232223433398065\n",
      "epoch 163, train loss 0.0008255762402855215\n",
      "epoch 163, train loss 0.07280791355740457\n",
      "epoch 164, train loss 0.0007941935725125765\n",
      "epoch 164, train loss 0.07315253720633567\n",
      "epoch 165, train loss 0.0007624888879483536\n",
      "epoch 165, train loss 0.07405689890895571\n",
      "epoch 166, train loss 0.0007327068560121078\n",
      "epoch 166, train loss 0.07256547840578216\n",
      "epoch 167, train loss 0.0007040921944223107\n",
      "epoch 167, train loss 0.07137627793209893\n",
      "epoch 168, train loss 0.0006778423096023737\n",
      "epoch 168, train loss 0.06710954276578766\n",
      "epoch 169, train loss 0.0006507233566870647\n",
      "epoch 169, train loss 0.07124565683660053\n",
      "epoch 170, train loss 0.0006250199863672374\n",
      "epoch 170, train loss 0.07241034874367336\n",
      "epoch 171, train loss 0.0006007776902397237\n",
      "epoch 171, train loss 0.06982419858612711\n",
      "epoch 172, train loss 0.0005779322634066736\n",
      "epoch 172, train loss 0.06974724975843279\n",
      "epoch 173, train loss 0.0005556112571087267\n",
      "epoch 173, train loss 0.06548455121025207\n",
      "epoch 174, train loss 0.0005340837478075945\n",
      "epoch 174, train loss 0.06942148140025517\n",
      "epoch 175, train loss 0.0005136227876406222\n",
      "epoch 175, train loss 0.06755874548403043\n",
      "epoch 176, train loss 0.0004942512208048905\n",
      "epoch 176, train loss 0.06797771971850168\n",
      "epoch 177, train loss 0.00047432556600561217\n",
      "epoch 177, train loss 0.06623892746274433\n",
      "epoch 178, train loss 0.00045633861251796287\n",
      "epoch 178, train loss 0.06369739179573362\n",
      "epoch 179, train loss 0.00043887682979749075\n",
      "epoch 179, train loss 0.06822995729153118\n",
      "epoch 180, train loss 0.0004217973776302108\n",
      "epoch 180, train loss 0.065972375313914\n",
      "epoch 181, train loss 0.00040639225866586444\n",
      "epoch 181, train loss 0.06607971393636294\n",
      "epoch 182, train loss 0.00039085185493431275\n",
      "epoch 182, train loss 0.06822564630281358\n",
      "epoch 183, train loss 0.0003752298690083008\n",
      "epoch 183, train loss 0.06049339449594891\n",
      "epoch 184, train loss 0.00036122174129732664\n",
      "epoch 184, train loss 0.06406965479254723\n",
      "epoch 185, train loss 0.0003475064591002015\n",
      "epoch 185, train loss 0.06466322611012155\n",
      "epoch 186, train loss 0.00033422954295510575\n",
      "epoch 186, train loss 0.06377019496664169\n",
      "epoch 187, train loss 0.00032130906835109706\n",
      "epoch 187, train loss 0.06523359815279643\n",
      "epoch 188, train loss 0.0003093582811757981\n",
      "epoch 188, train loss 0.06384984865075066\n",
      "epoch 189, train loss 0.00029766932869004824\n",
      "epoch 189, train loss 0.06131767700352366\n",
      "epoch 190, train loss 0.0002865173529633986\n",
      "epoch 190, train loss 0.06341921390285568\n",
      "epoch 191, train loss 0.00027556659141925\n",
      "epoch 191, train loss 0.06689272885994306\n",
      "epoch 192, train loss 0.0002650048741738179\n",
      "epoch 192, train loss 0.06388124663914953\n",
      "epoch 193, train loss 0.0002553593048581942\n",
      "epoch 193, train loss 0.06144364479751814\n",
      "epoch 194, train loss 0.0002456383778721035\n",
      "epoch 194, train loss 0.06262114691355872\n",
      "epoch 195, train loss 0.00023631315996190384\n",
      "epoch 195, train loss 0.06056152597542793\n",
      "epoch 196, train loss 0.00022754874653256837\n",
      "epoch 196, train loss 0.06213837448093626\n",
      "epoch 197, train loss 0.0002189539396019268\n",
      "epoch 197, train loss 0.06403000008255716\n",
      "epoch 198, train loss 0.00021102531080407697\n",
      "epoch 198, train loss 0.05962440992395083\n",
      "epoch 199, train loss 0.000202947849636927\n",
      "epoch 199, train loss 0.05957287603190967\n",
      "epoch 200, train loss 0.00019529341310743124\n",
      "epoch 200, train loss 0.0625182721941244\n"
     ]
    }
   ],
   "source": [
    "n_epochs=200\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model = model.float()\n",
    "    model_drop = model_drop.float()\n",
    "    # TRAINING\n",
    "    loss_value = 0.0\n",
    "    loss_drop_value = 0.0\n",
    "    for x, y in trainloader:\n",
    "        #train mode\n",
    "        model.train()\n",
    "        model_drop.train()\n",
    "        #clear gradient\n",
    "        optimizer_ofit.zero_grad()\n",
    "        optimizer_drop.zero_grad()\n",
    "        #make a prediction for both models\n",
    "        yhat = model(data_set.x)\n",
    "        yhat_drop = model_drop(data_set.x)\n",
    "        #calculate the lossf or both models\n",
    "        loss = criterion(yhat, data_set.y)\n",
    "        loss_drop = criterion(yhat_drop, data_set.y)\n",
    "        #accumulate loss for further analysis for both models\n",
    "        loss_value += loss.item()\n",
    "        loss_drop_value += loss_drop.item()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        loss_drop.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer_ofit.step()\n",
    "        optimizer_drop.step()\n",
    "        #store the loss for the training data for both models\n",
    "    loss_value = loss_value / len(trainloader)\n",
    "    loss_drop_value = loss_drop_value / len(trainloader)\n",
    "\n",
    "    LOSS['training data no dropout'].append(loss_value)\n",
    "    LOSS['training data dropout'].append(loss_drop_value)\n",
    "    print('epoch {}, train loss {}'.format(epoch, loss_value))\n",
    "    print('epoch {}, train loss {}'.format(epoch, loss_drop_value))\n",
    "\n",
    "    # # VALIDATION\n",
    "    # with torch.no_grad():\n",
    "    #     for x, y in trainloader:\n",
    "    #         model_drop.eval()\n",
    "    #         model_drop.train()\n",
    "    #         #make a prediction for both models\n",
    "    #         yhat = model(data_set.x)\n",
    "    #         yhat_drop = model_drop(data_set.x)\n",
    "    #         #calculate the lossf or both models\n",
    "    #         loss = criterion(yhat, data_set.y)\n",
    "    #         loss_drop = criterion(yhat_drop, data_set.y)\n",
    "    #         #store the loss for the validation data for both models\n",
    "    #         LOSS['validation data no dropout'].append(loss.item())\n",
    "    #         LOSS['validation data dropout'].append(loss_drop.item())\n",
    "    #         print('epoch {}, test loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,(n_epochs+1),1), LOSS['training data no dropout'], 'r--')\n",
    "plt.legend(['training data, no dropout', 'training data, dropout'])\n",
    "plt.xlabel('epochs')\n",
    "plt.xlim([0, (n_epochs+1)])\n",
    "plt.xticks(np.arange(0,(n_epochs+1),20))\n",
    "plt.ylabel('loss')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,(n_epochs+1),1), LOSS['training data dropout'], 'r--')\n",
    "plt.legend(['training data, dropout'])\n",
    "plt.xlabel('epochs')\n",
    "plt.xlim([0, (n_epochs+1)])\n",
    "plt.xticks(np.arange(0,(n_epochs+1),20))\n",
    "plt.ylabel('loss')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model(x_val)\n",
    "z_dropout = model_drop(x_val)\n",
    "\n",
    "_,yhat=torch.max(z.data,1)\n",
    "_,yhat_dropout=torch.max(z_dropout.data,1)\n",
    "\n",
    "eval_matrix = (pd.crosstab(y_val, yhat))\n",
    "eval_matrix_dropout = (pd.crosstab(y_val, yhat_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4140127388535032"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eval_matrix[0][0]+eval_matrix[1][1]+eval_matrix[2][2])/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3630573248407643"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eval_matrix_dropout[0][0]+eval_matrix_dropout[1][1]+eval_matrix_dropout[2][2])/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary WITHOUT dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stationary</th>\n",
       "      <th>Go-forward</th>\n",
       "      <th>Go-right</th>\n",
       "      <th>Go-backward</th>\n",
       "      <th>Go-left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.86624</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.92994</td>\n",
       "      <td>0.92357</td>\n",
       "      <td>0.89172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGF</th>\n",
       "      <td>0.78021</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.89575</td>\n",
       "      <td>0.89969</td>\n",
       "      <td>0.80186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGM</th>\n",
       "      <td>0.83983</td>\n",
       "      <td>0.88144</td>\n",
       "      <td>0.92661</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.87125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.79003</td>\n",
       "      <td>0.84052</td>\n",
       "      <td>0.90106</td>\n",
       "      <td>0.89988</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUPR</th>\n",
       "      <td>0.65591</td>\n",
       "      <td>0.61184</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>0.7545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCD</th>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.02229</td>\n",
       "      <td>0.00955</td>\n",
       "      <td>0.00637</td>\n",
       "      <td>0.02229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BM</th>\n",
       "      <td>0.58005</td>\n",
       "      <td>0.68103</td>\n",
       "      <td>0.80212</td>\n",
       "      <td>0.79977</td>\n",
       "      <td>0.63401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEN</th>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.53387</td>\n",
       "      <td>0.24647</td>\n",
       "      <td>0.28023</td>\n",
       "      <td>0.35009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR</th>\n",
       "      <td>0.13376</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.07006</td>\n",
       "      <td>0.07643</td>\n",
       "      <td>0.10828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F0.5</th>\n",
       "      <td>0.64935</td>\n",
       "      <td>0.51136</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.81967</td>\n",
       "      <td>0.79618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.58065</td>\n",
       "      <td>0.86747</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.74627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>0.66225</td>\n",
       "      <td>0.67164</td>\n",
       "      <td>0.84906</td>\n",
       "      <td>0.84746</td>\n",
       "      <td>0.70225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDR</th>\n",
       "      <td>0.35484</td>\n",
       "      <td>0.52632</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.18919</td>\n",
       "      <td>0.16667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16279</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>0.32432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOR</th>\n",
       "      <td>0.07937</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.05983</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.09449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.08661</td>\n",
       "      <td>0.06897</td>\n",
       "      <td>0.03509</td>\n",
       "      <td>0.05738</td>\n",
       "      <td>0.04167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.65583</td>\n",
       "      <td>0.59604</td>\n",
       "      <td>0.86804</td>\n",
       "      <td>0.83366</td>\n",
       "      <td>0.75038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>0.58005</td>\n",
       "      <td>0.68103</td>\n",
       "      <td>0.80212</td>\n",
       "      <td>0.79977</td>\n",
       "      <td>0.63401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.78034</td>\n",
       "      <td>0.83563</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.89887</td>\n",
       "      <td>0.80469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBA</th>\n",
       "      <td>0.45869</td>\n",
       "      <td>0.57186</td>\n",
       "      <td>0.70467</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.4645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICSI</th>\n",
       "      <td>0.31183</td>\n",
       "      <td>0.22368</td>\n",
       "      <td>0.73721</td>\n",
       "      <td>0.66795</td>\n",
       "      <td>0.50901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>1.75546</td>\n",
       "      <td>2.63166</td>\n",
       "      <td>1.71635</td>\n",
       "      <td>1.86277</td>\n",
       "      <td>1.82213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.40909</td>\n",
       "      <td>0.76596</td>\n",
       "      <td>0.71429</td>\n",
       "      <td>0.59524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS</th>\n",
       "      <td>3.37634</td>\n",
       "      <td>6.19737</td>\n",
       "      <td>3.28605</td>\n",
       "      <td>3.63707</td>\n",
       "      <td>3.53604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCEN</th>\n",
       "      <td>0.59962</td>\n",
       "      <td>0.65481</td>\n",
       "      <td>0.37125</td>\n",
       "      <td>0.40633</td>\n",
       "      <td>0.46758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>114</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLR</th>\n",
       "      <td>0.36494</td>\n",
       "      <td>0.26852</td>\n",
       "      <td>0.16871</td>\n",
       "      <td>0.15155</td>\n",
       "      <td>0.33843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.92063</td>\n",
       "      <td>0.97826</td>\n",
       "      <td>0.94017</td>\n",
       "      <td>0.95833</td>\n",
       "      <td>0.90551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC</th>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>0.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OOC</th>\n",
       "      <td>0.65583</td>\n",
       "      <td>0.59604</td>\n",
       "      <td>0.86804</td>\n",
       "      <td>0.83366</td>\n",
       "      <td>0.75038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP</th>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.80951</td>\n",
       "      <td>0.85907</td>\n",
       "      <td>0.87607</td>\n",
       "      <td>0.71874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLR</th>\n",
       "      <td>7.69697</td>\n",
       "      <td>10.875</td>\n",
       "      <td>23.86047</td>\n",
       "      <td>14.93878</td>\n",
       "      <td>16.21622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.64516</td>\n",
       "      <td>0.47368</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.81081</td>\n",
       "      <td>0.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.19108</td>\n",
       "      <td>0.07643</td>\n",
       "      <td>0.27389</td>\n",
       "      <td>0.22293</td>\n",
       "      <td>0.23567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACC</th>\n",
       "      <td>0.03773</td>\n",
       "      <td>0.00925</td>\n",
       "      <td>0.06978</td>\n",
       "      <td>0.05254</td>\n",
       "      <td>0.04503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACCU</th>\n",
       "      <td>0.03774</td>\n",
       "      <td>0.00975</td>\n",
       "      <td>0.06987</td>\n",
       "      <td>0.05258</td>\n",
       "      <td>0.04553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>116</td>\n",
       "      <td>135</td>\n",
       "      <td>110</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.91339</td>\n",
       "      <td>0.93103</td>\n",
       "      <td>0.96491</td>\n",
       "      <td>0.94262</td>\n",
       "      <td>0.95833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TON</th>\n",
       "      <td>126</td>\n",
       "      <td>138</td>\n",
       "      <td>117</td>\n",
       "      <td>120</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOP</th>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83721</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>0.67568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.58005</td>\n",
       "      <td>0.68103</td>\n",
       "      <td>0.80212</td>\n",
       "      <td>0.79977</td>\n",
       "      <td>0.63401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dInd</th>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.25934</td>\n",
       "      <td>0.16653</td>\n",
       "      <td>0.15395</td>\n",
       "      <td>0.32699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sInd</th>\n",
       "      <td>0.75647</td>\n",
       "      <td>0.81662</td>\n",
       "      <td>0.88225</td>\n",
       "      <td>0.89114</td>\n",
       "      <td>0.76878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Stationary Go-forward  Go-right Go-backward   Go-left\n",
       "Class                                                      \n",
       "ACC      0.86624     0.9172   0.92994     0.92357   0.89172\n",
       "AGF      0.78021     0.8065   0.89575     0.89969   0.80186\n",
       "AGM      0.83983    0.88144   0.92661       0.918   0.87125\n",
       "AUC      0.79003    0.84052   0.90106     0.89988     0.817\n",
       "AUPR     0.65591    0.61184    0.8686     0.83398    0.7545\n",
       "BCD      0.00318    0.02229   0.00955     0.00637   0.02229\n",
       "BM       0.58005    0.68103   0.80212     0.79977   0.63401\n",
       "CEN       0.4688    0.53387   0.24647     0.28023   0.35009\n",
       "ERR      0.13376     0.0828   0.07006     0.07643   0.10828\n",
       "F0.5     0.64935    0.51136    0.8867     0.81967   0.79618\n",
       "F1       0.65574    0.58065   0.86747     0.83333   0.74627\n",
       "F2       0.66225    0.67164   0.84906     0.84746   0.70225\n",
       "FDR      0.35484    0.52632       0.1     0.18919   0.16667\n",
       "FN            10          3         7           5        12\n",
       "FNR      0.33333       0.25   0.16279     0.14286   0.32432\n",
       "FOR      0.07937    0.02174   0.05983     0.04167   0.09449\n",
       "FP            11         10         4           7         5\n",
       "FPR      0.08661    0.06897   0.03509     0.05738   0.04167\n",
       "G        0.65583    0.59604   0.86804     0.83366   0.75038\n",
       "GI       0.58005    0.68103   0.80212     0.79977   0.63401\n",
       "GM       0.78034    0.83563    0.8988     0.89887   0.80469\n",
       "IBA      0.45869    0.57186   0.70467      0.7389    0.4645\n",
       "ICSI     0.31183    0.22368   0.73721     0.66795   0.50901\n",
       "IS       1.75546    2.63166   1.71635     1.86277   1.82213\n",
       "J         0.4878    0.40909   0.76596     0.71429   0.59524\n",
       "LS       3.37634    6.19737   3.28605     3.63707   3.53604\n",
       "MCEN     0.59962    0.65481   0.37125     0.40633   0.46758\n",
       "N            127        145       114         122       120\n",
       "NLR      0.36494    0.26852   0.16871     0.15155   0.33843\n",
       "NPV      0.92063    0.97826   0.94017     0.95833   0.90551\n",
       "OC       0.66667       0.75       0.9     0.85714   0.83333\n",
       "OOC      0.65583    0.59604   0.86804     0.83366   0.75038\n",
       "OP        0.7101    0.80951   0.85907     0.87607   0.71874\n",
       "P             30         12        43          35        37\n",
       "PLR      7.69697     10.875  23.86047    14.93878  16.21622\n",
       "POP          157        157       157         157       157\n",
       "PPV      0.64516    0.47368       0.9     0.81081   0.83333\n",
       "PRE      0.19108    0.07643   0.27389     0.22293   0.23567\n",
       "RACC     0.03773    0.00925   0.06978     0.05254   0.04503\n",
       "RACCU    0.03774    0.00975   0.06987     0.05258   0.04553\n",
       "TN           116        135       110         115       115\n",
       "TNR      0.91339    0.93103   0.96491     0.94262   0.95833\n",
       "TON          126        138       117         120       127\n",
       "TOP           31         19        40          37        30\n",
       "TP            20          9        36          30        25\n",
       "TPR      0.66667       0.75   0.83721     0.85714   0.67568\n",
       "Y        0.58005    0.68103   0.80212     0.79977   0.63401\n",
       "dInd      0.3444    0.25934   0.16653     0.15395   0.32699\n",
       "sInd     0.75647    0.81662   0.88225     0.89114   0.76878"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['ACC'\n",
    "                    ,'AGF'\n",
    "                    ,'AGM'\n",
    "                    ,'AUC'\n",
    "                    ,'AUPR'\n",
    "                    ,'BCD'\n",
    "                    ,'BM'\n",
    "                    ,'CEN'\n",
    "                    ,'ERR'\n",
    "                    ,'F0.5'\n",
    "                    ,'F1'\n",
    "                    ,'F2'\n",
    "                    ,'FDR'\n",
    "                    ,'FN'\n",
    "                    ,'FNR'\n",
    "                    ,'FOR'\n",
    "                    ,'FP'\n",
    "                    ,'FPR'\n",
    "                    ,'G'\n",
    "                    ,'GI'\n",
    "                    ,'GM'\n",
    "                    ,'IBA'\n",
    "                    ,'ICSI'\n",
    "                    ,'IS'\n",
    "                    ,'J'\n",
    "                    ,'LS'\n",
    "                    ,'MCEN'\n",
    "                    ,'N'\n",
    "                    ,'NLR'\n",
    "                    ,'NPV'\n",
    "                    ,'OC'\n",
    "                    ,'OOC'\n",
    "                    ,'OP'\n",
    "                    ,'P'\n",
    "                    ,'PLR'\n",
    "                    ,'POP'\n",
    "                    ,'PPV'\n",
    "                    ,'PRE'\n",
    "                    ,'RACC'\n",
    "                    ,'RACCU'\n",
    "                    ,'TN'\n",
    "                    ,'TNR'\n",
    "                    ,'TON'\n",
    "                    ,'TOP'\n",
    "                    ,'TP'\n",
    "                    ,'TPR'\n",
    "                    ,'Y'\n",
    "                    ,'dInd'\n",
    "                    ,'sInd']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()\n",
    "inputs, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(inputs)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, x)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary WITH dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat_dropout))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stationary</th>\n",
       "      <th>Go-forward</th>\n",
       "      <th>Go-right</th>\n",
       "      <th>Go-backward</th>\n",
       "      <th>Go-left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.85987</td>\n",
       "      <td>0.92994</td>\n",
       "      <td>0.87898</td>\n",
       "      <td>0.90446</td>\n",
       "      <td>0.89172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGF</th>\n",
       "      <td>0.64859</td>\n",
       "      <td>0.69875</td>\n",
       "      <td>0.89118</td>\n",
       "      <td>0.86499</td>\n",
       "      <td>0.86389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGM</th>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.82478</td>\n",
       "      <td>0.87908</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>0.88575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.69698</td>\n",
       "      <td>0.73276</td>\n",
       "      <td>0.88046</td>\n",
       "      <td>0.86721</td>\n",
       "      <td>0.86374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUPR</th>\n",
       "      <td>0.57778</td>\n",
       "      <td>0.52273</td>\n",
       "      <td>0.80725</td>\n",
       "      <td>0.78889</td>\n",
       "      <td>0.78041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCD</th>\n",
       "      <td>0.03822</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.02866</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.00955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BM</th>\n",
       "      <td>0.39396</td>\n",
       "      <td>0.46552</td>\n",
       "      <td>0.76091</td>\n",
       "      <td>0.73443</td>\n",
       "      <td>0.72748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEN</th>\n",
       "      <td>0.55198</td>\n",
       "      <td>0.48543</td>\n",
       "      <td>0.32478</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.34918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR</th>\n",
       "      <td>0.14013</td>\n",
       "      <td>0.07006</td>\n",
       "      <td>0.12102</td>\n",
       "      <td>0.09554</td>\n",
       "      <td>0.10828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F0.5</th>\n",
       "      <td>0.63725</td>\n",
       "      <td>0.53571</td>\n",
       "      <td>0.75697</td>\n",
       "      <td>0.78212</td>\n",
       "      <td>0.76142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.54167</td>\n",
       "      <td>0.52174</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.78873</td>\n",
       "      <td>0.77922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>0.47101</td>\n",
       "      <td>0.50847</td>\n",
       "      <td>0.84821</td>\n",
       "      <td>0.79545</td>\n",
       "      <td>0.79787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDR</th>\n",
       "      <td>0.27778</td>\n",
       "      <td>0.45455</td>\n",
       "      <td>0.26923</td>\n",
       "      <td>0.22222</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.11628</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.18919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOR</th>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.04762</td>\n",
       "      <td>0.05785</td>\n",
       "      <td>0.05983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.03937</td>\n",
       "      <td>0.03448</td>\n",
       "      <td>0.12281</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0.08333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.55943</td>\n",
       "      <td>0.52223</td>\n",
       "      <td>0.80361</td>\n",
       "      <td>0.78881</td>\n",
       "      <td>0.77981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>0.39396</td>\n",
       "      <td>0.46552</td>\n",
       "      <td>0.76091</td>\n",
       "      <td>0.73443</td>\n",
       "      <td>0.72748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.64519</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.88045</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>0.86212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBA</th>\n",
       "      <td>0.19677</td>\n",
       "      <td>0.25803</td>\n",
       "      <td>0.78025</td>\n",
       "      <td>0.64705</td>\n",
       "      <td>0.66457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICSI</th>\n",
       "      <td>0.15556</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>0.61449</td>\n",
       "      <td>0.57778</td>\n",
       "      <td>0.56081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>1.91824</td>\n",
       "      <td>2.83519</td>\n",
       "      <td>1.41584</td>\n",
       "      <td>1.80277</td>\n",
       "      <td>1.67013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0.37143</td>\n",
       "      <td>0.35294</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.65116</td>\n",
       "      <td>0.6383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS</th>\n",
       "      <td>3.77963</td>\n",
       "      <td>7.13636</td>\n",
       "      <td>2.66816</td>\n",
       "      <td>3.48889</td>\n",
       "      <td>3.18243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCEN</th>\n",
       "      <td>0.66153</td>\n",
       "      <td>0.56269</td>\n",
       "      <td>0.45942</td>\n",
       "      <td>0.46422</td>\n",
       "      <td>0.4862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>114</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLR</th>\n",
       "      <td>0.58989</td>\n",
       "      <td>0.51786</td>\n",
       "      <td>0.13256</td>\n",
       "      <td>0.21404</td>\n",
       "      <td>0.20639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.95238</td>\n",
       "      <td>0.94215</td>\n",
       "      <td>0.94017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC</th>\n",
       "      <td>0.72222</td>\n",
       "      <td>0.54545</td>\n",
       "      <td>0.88372</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OOC</th>\n",
       "      <td>0.55943</td>\n",
       "      <td>0.52223</td>\n",
       "      <td>0.80361</td>\n",
       "      <td>0.78881</td>\n",
       "      <td>0.77981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP</th>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.87527</td>\n",
       "      <td>0.82695</td>\n",
       "      <td>0.83044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLR</th>\n",
       "      <td>11.00667</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.19601</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9.72973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.72222</td>\n",
       "      <td>0.54545</td>\n",
       "      <td>0.73077</td>\n",
       "      <td>0.77778</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.19108</td>\n",
       "      <td>0.07643</td>\n",
       "      <td>0.27389</td>\n",
       "      <td>0.22293</td>\n",
       "      <td>0.23567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACC</th>\n",
       "      <td>0.02191</td>\n",
       "      <td>0.00536</td>\n",
       "      <td>0.09071</td>\n",
       "      <td>0.05112</td>\n",
       "      <td>0.06004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACCU</th>\n",
       "      <td>0.02337</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.09154</td>\n",
       "      <td>0.05113</td>\n",
       "      <td>0.06013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>122</td>\n",
       "      <td>140</td>\n",
       "      <td>100</td>\n",
       "      <td>114</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.96063</td>\n",
       "      <td>0.96552</td>\n",
       "      <td>0.87719</td>\n",
       "      <td>0.93443</td>\n",
       "      <td>0.91667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TON</th>\n",
       "      <td>139</td>\n",
       "      <td>146</td>\n",
       "      <td>105</td>\n",
       "      <td>121</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOP</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.43333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88372</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.39396</td>\n",
       "      <td>0.46552</td>\n",
       "      <td>0.76091</td>\n",
       "      <td>0.73443</td>\n",
       "      <td>0.72748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dInd</th>\n",
       "      <td>0.56803</td>\n",
       "      <td>0.50119</td>\n",
       "      <td>0.16912</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.20673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sInd</th>\n",
       "      <td>0.59834</td>\n",
       "      <td>0.64561</td>\n",
       "      <td>0.88041</td>\n",
       "      <td>0.85117</td>\n",
       "      <td>0.85382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Stationary Go-forward Go-right Go-backward  Go-left\n",
       "Class                                                    \n",
       "ACC      0.85987    0.92994  0.87898     0.90446  0.89172\n",
       "AGF      0.64859    0.69875  0.89118     0.86499  0.86389\n",
       "AGM      0.78625    0.82478  0.87908     0.89514  0.88575\n",
       "AUC      0.69698    0.73276  0.88046     0.86721  0.86374\n",
       "AUPR     0.57778    0.52273  0.80725     0.78889  0.78041\n",
       "BCD      0.03822    0.00318  0.02866     0.00318  0.00955\n",
       "BM       0.39396    0.46552  0.76091     0.73443  0.72748\n",
       "CEN      0.55198    0.48543  0.32478      0.3321  0.34918\n",
       "ERR      0.14013    0.07006  0.12102     0.09554  0.10828\n",
       "F0.5     0.63725    0.53571  0.75697     0.78212  0.76142\n",
       "F1       0.54167    0.52174      0.8     0.78873  0.77922\n",
       "F2       0.47101    0.50847  0.84821     0.79545  0.79787\n",
       "FDR      0.27778    0.45455  0.26923     0.22222     0.25\n",
       "FN            17          6        5           7        7\n",
       "FNR      0.56667        0.5  0.11628         0.2  0.18919\n",
       "FOR       0.1223     0.0411  0.04762     0.05785  0.05983\n",
       "FP             5          5       14           8       10\n",
       "FPR      0.03937    0.03448  0.12281     0.06557  0.08333\n",
       "G        0.55943    0.52223  0.80361     0.78881  0.77981\n",
       "GI       0.39396    0.46552  0.76091     0.73443  0.72748\n",
       "GM       0.64519    0.69481  0.88045      0.8646  0.86212\n",
       "IBA      0.19677    0.25803  0.78025     0.64705  0.66457\n",
       "ICSI     0.15556    0.04545  0.61449     0.57778  0.56081\n",
       "IS       1.91824    2.83519  1.41584     1.80277  1.67013\n",
       "J        0.37143    0.35294  0.66667     0.65116   0.6383\n",
       "LS       3.77963    7.13636  2.66816     3.48889  3.18243\n",
       "MCEN     0.66153    0.56269  0.45942     0.46422   0.4862\n",
       "N            127        145      114         122      120\n",
       "NLR      0.58989    0.51786  0.13256     0.21404  0.20639\n",
       "NPV       0.8777     0.9589  0.95238     0.94215  0.94017\n",
       "OC       0.72222    0.54545  0.88372         0.8  0.81081\n",
       "OOC      0.55943    0.52223  0.80361     0.78881  0.77981\n",
       "OP        0.4816    0.61229  0.87527     0.82695  0.83044\n",
       "P             30         12       43          35       37\n",
       "PLR     11.00667       14.5  7.19601        12.2  9.72973\n",
       "POP          157        157      157         157      157\n",
       "PPV      0.72222    0.54545  0.73077     0.77778     0.75\n",
       "PRE      0.19108    0.07643  0.27389     0.22293  0.23567\n",
       "RACC     0.02191    0.00536  0.09071     0.05112  0.06004\n",
       "RACCU    0.02337    0.00537  0.09154     0.05113  0.06013\n",
       "TN           122        140      100         114      110\n",
       "TNR      0.96063    0.96552  0.87719     0.93443  0.91667\n",
       "TON          139        146      105         121      117\n",
       "TOP           18         11       52          36       40\n",
       "TP            13          6       38          28       30\n",
       "TPR      0.43333        0.5  0.88372         0.8  0.81081\n",
       "Y        0.39396    0.46552  0.76091     0.73443  0.72748\n",
       "dInd     0.56803    0.50119  0.16912     0.21048  0.20673\n",
       "sInd     0.59834    0.64561  0.88041     0.85117  0.85382"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat_dropout))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['ACC'\n",
    "                    ,'AGF'\n",
    "                    ,'AGM'\n",
    "                    ,'AUC'\n",
    "                    ,'AUPR'\n",
    "                    ,'BCD'\n",
    "                    ,'BM'\n",
    "                    ,'CEN'\n",
    "                    ,'ERR'\n",
    "                    ,'F0.5'\n",
    "                    ,'F1'\n",
    "                    ,'F2'\n",
    "                    ,'FDR'\n",
    "                    ,'FN'\n",
    "                    ,'FNR'\n",
    "                    ,'FOR'\n",
    "                    ,'FP'\n",
    "                    ,'FPR'\n",
    "                    ,'G'\n",
    "                    ,'GI'\n",
    "                    ,'GM'\n",
    "                    ,'IBA'\n",
    "                    ,'ICSI'\n",
    "                    ,'IS'\n",
    "                    ,'J'\n",
    "                    ,'LS'\n",
    "                    ,'MCEN'\n",
    "                    ,'N'\n",
    "                    ,'NLR'\n",
    "                    ,'NPV'\n",
    "                    ,'OC'\n",
    "                    ,'OOC'\n",
    "                    ,'OP'\n",
    "                    ,'P'\n",
    "                    ,'PLR'\n",
    "                    ,'POP'\n",
    "                    ,'PPV'\n",
    "                    ,'PRE'\n",
    "                    ,'RACC'\n",
    "                    ,'RACCU'\n",
    "                    ,'TN'\n",
    "                    ,'TNR'\n",
    "                    ,'TON'\n",
    "                    ,'TOP'\n",
    "                    ,'TP'\n",
    "                    ,'TPR'\n",
    "                    ,'Y'\n",
    "                    ,'dInd'\n",
    "                    ,'sInd']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()\n",
    "inputs, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(inputs)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model_drop, x)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 layer feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = pd.read_csv('skeleton_column_names.csv', header=None)[0].to_list()\n",
    "new_labels = pd.read_csv('skeleton_labels.csv', header=None)[0].to_list()\n",
    "\n",
    "df_skeleton = pd.read_csv('datasets/PedCut2013_SegmentationDataset/keypoints.json.udt.csv')\n",
    "df_skeleton = df_skeleton[new_labels]\n",
    "df_skeleton.columns = new_column_names\n",
    "df_skeleton.dropna(inplace=True)\n",
    "\n",
    "df_classification = pd.read_csv('datasets/PedCut2013_SegmentationDataset/classification.json.udt.csv')\n",
    "df_classification = df_classification[['imageUrl', 'annotation']]\n",
    "df_classification.dropna(inplace=True)\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "df_classification.columns = ['imageUrl', 'classification']\n",
    "\n",
    "merged_df = df_skeleton.merge(df_classification, how = 'inner', on = ['imageUrl'])\n",
    "new_column_names.pop(0)\n",
    "df_skeleton = merged_df[new_column_names]\n",
    "\n",
    "df_classification = merged_df['classification']\n",
    "df_classification = pd.DataFrame(df_classification)\n",
    "\n",
    "df_classification['simplified_classification'] = np.where(df_classification['classification'] == 'stationary', 0,\\\n",
    "    np.where(df_classification['classification'] == 'go-forward', 1,\\\n",
    "    np.where(df_classification['classification'] == 'go-right', 2,\\\n",
    "    np.where(df_classification['classification'] == 'go-backward', 3,\\\n",
    "    np.where(df_classification['classification'] == 'go-left', 4, np.nan)))))\n",
    "\n",
    "y_actual = np.array(df_classification['simplified_classification'])\n",
    "\n",
    "ncut = int(len(y_actual)*0.8)\n",
    "\n",
    "y = y_actual[:ncut]\n",
    "y_val = y_actual[ncut:]\n",
    "\n",
    "x = np.array(df_skeleton[:ncut])\n",
    "x_val = np.array(df_skeleton[ncut:])\n",
    "\n",
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val\n",
    "\n",
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x).type(torch.FloatTensor)\n",
    "        self.y=torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_set=Data()\n",
    "trainloader=DataLoader(dataset=data_set,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,in_size,n_hidden1,n_hidden2,out_size,p=0):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        self.drop=nn.Dropout(p=p)\n",
    "        self.linear1=nn.Linear(in_size,n_hidden1)\n",
    "        # nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear2=nn.Linear(n_hidden1,n_hidden2)\n",
    "        # nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear3=nn.Linear(n_hidden2,n_hidden2)\n",
    "        # nn.init.kaiming_uniform_(self.linear3.weight,nonlinearity='relu')\n",
    "        self.linear4=nn.Linear(n_hidden2,out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.linear1(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear2(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear3(x))\n",
    "        x=self.drop(x)\n",
    "        x=self.linear4(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Net(34, 68, 68, 5)\n",
    "model_drop = Net(34, 68, 68, 5, p=0.2)\n",
    "\n",
    "optimizer_ofit = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer_drop = torch.optim.Adam(model_drop.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "LOSS={}\n",
    "LOSS['training data no dropout']=[]\n",
    "LOSS['validation data no dropout']=[]\n",
    "LOSS['training data dropout']=[]\n",
    "LOSS['validation data dropout']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss 1.4551018590018863\n",
      "epoch 1, train loss 1.4665522915976388\n",
      "epoch 2, train loss 0.9389415430644202\n",
      "epoch 2, train loss 0.9623466578740922\n",
      "epoch 3, train loss 0.7575892351922535\n",
      "epoch 3, train loss 0.8175610918847341\n",
      "epoch 4, train loss 0.7030710142756266\n",
      "epoch 4, train loss 0.7686502886196923\n",
      "epoch 5, train loss 0.6619656842852396\n",
      "epoch 5, train loss 0.7215892587389264\n",
      "epoch 6, train loss 0.6085104516574315\n",
      "epoch 6, train loss 0.6704807905923753\n",
      "epoch 7, train loss 0.5268506965939961\n",
      "epoch 7, train loss 0.6259837519554865\n",
      "epoch 8, train loss 0.46281101117058404\n",
      "epoch 8, train loss 0.5942721745324513\n",
      "epoch 9, train loss 0.42672769938196453\n",
      "epoch 9, train loss 0.5657312453739227\n",
      "epoch 10, train loss 0.4024517933527629\n",
      "epoch 10, train loss 0.5455815565018427\n",
      "epoch 11, train loss 0.38359694963409785\n",
      "epoch 11, train loss 0.5222320258617401\n",
      "epoch 12, train loss 0.3676103362961421\n",
      "epoch 12, train loss 0.5035313703711071\n",
      "epoch 13, train loss 0.3538451109613691\n",
      "epoch 13, train loss 0.481509379451237\n",
      "epoch 14, train loss 0.3398966089127556\n",
      "epoch 14, train loss 0.4667172942842756\n",
      "epoch 15, train loss 0.3269060845412905\n",
      "epoch 15, train loss 0.44640689851745724\n",
      "epoch 16, train loss 0.31456814446146525\n",
      "epoch 16, train loss 0.4318801145704966\n",
      "epoch 17, train loss 0.3025143917590853\n",
      "epoch 17, train loss 0.41595933219743153\n",
      "epoch 18, train loss 0.2901012731922997\n",
      "epoch 18, train loss 0.4003256805359371\n",
      "epoch 19, train loss 0.2781453435383146\n",
      "epoch 19, train loss 0.3794119755427043\n",
      "epoch 20, train loss 0.2668219080993107\n",
      "epoch 20, train loss 0.3708490019752866\n",
      "epoch 21, train loss 0.2549920879186146\n",
      "epoch 21, train loss 0.3552511258730813\n",
      "epoch 22, train loss 0.24371966554058921\n",
      "epoch 22, train loss 0.3458679990162925\n",
      "epoch 23, train loss 0.23233584870421697\n",
      "epoch 23, train loss 0.33290583462942214\n",
      "epoch 24, train loss 0.22132957241837942\n",
      "epoch 24, train loss 0.3205040726396773\n",
      "epoch 25, train loss 0.21009578662259237\n",
      "epoch 25, train loss 0.31006340753464473\n",
      "epoch 26, train loss 0.19904210170110068\n",
      "epoch 26, train loss 0.29749270232896957\n",
      "epoch 27, train loss 0.18822136497686778\n",
      "epoch 27, train loss 0.2876362767484453\n",
      "epoch 28, train loss 0.17869891746649666\n",
      "epoch 28, train loss 0.27959528163311975\n",
      "epoch 29, train loss 0.1687397774722841\n",
      "epoch 29, train loss 0.26746392462934765\n",
      "epoch 30, train loss 0.15988204072392176\n",
      "epoch 30, train loss 0.262989946774074\n",
      "epoch 31, train loss 0.1513662664663224\n",
      "epoch 31, train loss 0.2551468773966744\n",
      "epoch 32, train loss 0.1433395485556315\n",
      "epoch 32, train loss 0.24594395903367844\n",
      "epoch 33, train loss 0.13525718474198903\n",
      "epoch 33, train loss 0.2342146975653512\n",
      "epoch 34, train loss 0.1264617039807259\n",
      "epoch 34, train loss 0.23444880355918218\n",
      "epoch 35, train loss 0.1202857806569054\n",
      "epoch 35, train loss 0.22534258072338406\n",
      "epoch 36, train loss 0.11209393623802397\n",
      "epoch 36, train loss 0.2164243379282573\n",
      "epoch 37, train loss 0.10620895678561831\n",
      "epoch 37, train loss 0.211263740819598\n",
      "epoch 38, train loss 0.10013385684717269\n",
      "epoch 38, train loss 0.2039432873328527\n",
      "epoch 39, train loss 0.09448094547740997\n",
      "epoch 39, train loss 0.20305046084381284\n",
      "epoch 40, train loss 0.0894214916560385\n",
      "epoch 40, train loss 0.19887911232690964\n",
      "epoch 41, train loss 0.08341676363396267\n",
      "epoch 41, train loss 0.19295775890350342\n",
      "epoch 42, train loss 0.07871739743720918\n",
      "epoch 42, train loss 0.1855854992828672\n",
      "epoch 43, train loss 0.07429085187022648\n",
      "epoch 43, train loss 0.18448227407440307\n",
      "epoch 44, train loss 0.06896477393687718\n",
      "epoch 44, train loss 0.17453381395529186\n",
      "epoch 45, train loss 0.06524375938470402\n",
      "epoch 45, train loss 0.1665904526672666\n",
      "epoch 46, train loss 0.060564094592654515\n",
      "epoch 46, train loss 0.17378083391795082\n",
      "epoch 47, train loss 0.057097001267330985\n",
      "epoch 47, train loss 0.17129411229065486\n",
      "epoch 48, train loss 0.05353526623239593\n",
      "epoch 48, train loss 0.15698358416557312\n",
      "epoch 49, train loss 0.050124357439695844\n",
      "epoch 49, train loss 0.1588680732344824\n",
      "epoch 50, train loss 0.04543898160022403\n",
      "epoch 50, train loss 0.1520696281204148\n",
      "epoch 51, train loss 0.04231737181544304\n",
      "epoch 51, train loss 0.1530238071840907\n",
      "epoch 52, train loss 0.03871357216248437\n",
      "epoch 52, train loss 0.15267079548230247\n",
      "epoch 53, train loss 0.03584975021935645\n",
      "epoch 53, train loss 0.14580781379389385\n",
      "epoch 54, train loss 0.033070213915336696\n",
      "epoch 54, train loss 0.14438312938289036\n",
      "epoch 55, train loss 0.030531533565076572\n",
      "epoch 55, train loss 0.14008155760783997\n",
      "epoch 56, train loss 0.02841679553782183\n",
      "epoch 56, train loss 0.13778996467590332\n",
      "epoch 57, train loss 0.02615175972737017\n",
      "epoch 57, train loss 0.1361194955451148\n",
      "epoch 58, train loss 0.02412876868177028\n",
      "epoch 58, train loss 0.13559148425147646\n",
      "epoch 59, train loss 0.022271179579316625\n",
      "epoch 59, train loss 0.13490683195136843\n",
      "epoch 60, train loss 0.020680777669425995\n",
      "epoch 60, train loss 0.12602383501472927\n",
      "epoch 61, train loss 0.018964574125314517\n",
      "epoch 61, train loss 0.12446662180480503\n",
      "epoch 62, train loss 0.01747889627539922\n",
      "epoch 62, train loss 0.11650058035812681\n",
      "epoch 63, train loss 0.016114512088871193\n",
      "epoch 63, train loss 0.12703643940270892\n",
      "epoch 64, train loss 0.01488473087490078\n",
      "epoch 64, train loss 0.11765873420333105\n",
      "epoch 65, train loss 0.013648302249965213\n",
      "epoch 65, train loss 0.1185828543135098\n",
      "epoch 66, train loss 0.01258432384698637\n",
      "epoch 66, train loss 0.1166803486763485\n",
      "epoch 67, train loss 0.011573390813455695\n",
      "epoch 67, train loss 0.11386170060861678\n",
      "epoch 68, train loss 0.010709164501537406\n",
      "epoch 68, train loss 0.11152549300874982\n",
      "epoch 69, train loss 0.00989080077066781\n",
      "epoch 69, train loss 0.11103701402270605\n",
      "epoch 70, train loss 0.009114436036537565\n",
      "epoch 70, train loss 0.10469832271337509\n",
      "epoch 71, train loss 0.008467716224018543\n",
      "epoch 71, train loss 0.09968015575219714\n",
      "epoch 72, train loss 0.007859765537201411\n",
      "epoch 72, train loss 0.10430969948333407\n",
      "epoch 73, train loss 0.007309373401637588\n",
      "epoch 73, train loss 0.10452972778252193\n",
      "epoch 74, train loss 0.006802008524241429\n",
      "epoch 74, train loss 0.10355654914700796\n",
      "epoch 75, train loss 0.00634869108242648\n",
      "epoch 75, train loss 0.10042669145124299\n",
      "epoch 76, train loss 0.005901403998630861\n",
      "epoch 76, train loss 0.09823527967646009\n",
      "epoch 77, train loss 0.0054975706670019366\n",
      "epoch 77, train loss 0.09672121242398307\n",
      "epoch 78, train loss 0.005133206667822032\n",
      "epoch 78, train loss 0.09493001816528183\n",
      "epoch 79, train loss 0.004796857716486094\n",
      "epoch 79, train loss 0.09700623923350894\n",
      "epoch 80, train loss 0.004488550932220523\n",
      "epoch 80, train loss 0.09208226688797512\n",
      "epoch 81, train loss 0.004199173626682115\n",
      "epoch 81, train loss 0.08705568402296021\n",
      "epoch 82, train loss 0.003936450259523496\n",
      "epoch 82, train loss 0.09420690519942178\n",
      "epoch 83, train loss 0.0036922653006123646\n",
      "epoch 83, train loss 0.09340055795416\n",
      "epoch 84, train loss 0.0034606014230539875\n",
      "epoch 84, train loss 0.08714877021691156\n",
      "epoch 85, train loss 0.0032495721760723325\n",
      "epoch 85, train loss 0.092370414781192\n",
      "epoch 86, train loss 0.0030598476684341827\n",
      "epoch 86, train loss 0.09175555035471916\n",
      "epoch 87, train loss 0.002875280732821141\n",
      "epoch 87, train loss 0.09086488346968379\n",
      "epoch 88, train loss 0.0027029928049102188\n",
      "epoch 88, train loss 0.08476326041041858\n",
      "epoch 89, train loss 0.002547533576568914\n",
      "epoch 89, train loss 0.08631582055536527\n",
      "epoch 90, train loss 0.002400347427095449\n",
      "epoch 90, train loss 0.08839441628919707\n",
      "epoch 91, train loss 0.0022632440382112113\n",
      "epoch 91, train loss 0.08458496511928619\n",
      "epoch 92, train loss 0.0021353204039827227\n",
      "epoch 92, train loss 0.08091477245565444\n",
      "epoch 93, train loss 0.0020158542098388786\n",
      "epoch 93, train loss 0.07890183029193727\n",
      "epoch 94, train loss 0.0019043220487970209\n",
      "epoch 94, train loss 0.08033231947393644\n",
      "epoch 95, train loss 0.0017732977368203656\n",
      "epoch 95, train loss 0.08943516536364479\n",
      "epoch 96, train loss 0.0016707502867257785\n",
      "epoch 96, train loss 0.07522387081195438\n",
      "epoch 97, train loss 0.0015790796938485333\n",
      "epoch 97, train loss 0.08008718029374168\n",
      "epoch 98, train loss 0.0014930988425418499\n",
      "epoch 98, train loss 0.07733843191748574\n",
      "epoch 99, train loss 0.0014164838865990677\n",
      "epoch 99, train loss 0.07642619820341232\n",
      "epoch 100, train loss 0.001340120544819723\n",
      "epoch 100, train loss 0.07736539610085033\n",
      "epoch 101, train loss 0.001270957753091814\n",
      "epoch 101, train loss 0.07527999100940568\n",
      "epoch 102, train loss 0.001205652577078177\n",
      "epoch 102, train loss 0.07306615115394668\n",
      "epoch 103, train loss 0.0011441072667135843\n",
      "epoch 103, train loss 0.0740517411558401\n",
      "epoch 104, train loss 0.0010858243054133795\n",
      "epoch 104, train loss 0.07537047358022796\n",
      "epoch 105, train loss 0.0010315113819189489\n",
      "epoch 105, train loss 0.07398248718134941\n",
      "epoch 106, train loss 0.0009804512586607229\n",
      "epoch 106, train loss 0.07349199908120292\n",
      "epoch 107, train loss 0.0009319368428328918\n",
      "epoch 107, train loss 0.07121147037971587\n",
      "epoch 108, train loss 0.0008849366974558622\n",
      "epoch 108, train loss 0.068109623437363\n",
      "epoch 109, train loss 0.0008412709049437018\n",
      "epoch 109, train loss 0.0694072377823648\n",
      "epoch 110, train loss 0.0008006726617052678\n",
      "epoch 110, train loss 0.07269895118143824\n",
      "epoch 111, train loss 0.0007625123447117707\n",
      "epoch 111, train loss 0.07245018345022959\n",
      "epoch 112, train loss 0.0007255280774737162\n",
      "epoch 112, train loss 0.0712857957160662\n",
      "epoch 113, train loss 0.0006907838054873522\n",
      "epoch 113, train loss 0.0709178311720727\n",
      "epoch 114, train loss 0.0006583919332894896\n",
      "epoch 114, train loss 0.0750253518067655\n",
      "epoch 115, train loss 0.0006274803327248683\n",
      "epoch 115, train loss 0.07182120389881588\n",
      "epoch 116, train loss 0.0005975828177133013\n",
      "epoch 116, train loss 0.06588047453098828\n",
      "epoch 117, train loss 0.000569647119846195\n",
      "epoch 117, train loss 0.07430753525760439\n",
      "epoch 118, train loss 0.0005433535487908456\n",
      "epoch 118, train loss 0.0741746567544483\n",
      "epoch 119, train loss 0.0005187606143336448\n",
      "epoch 119, train loss 0.06980355060289777\n",
      "epoch 120, train loss 0.0004946022019130252\n",
      "epoch 120, train loss 0.0677363562087218\n",
      "epoch 121, train loss 0.00047155044047117586\n",
      "epoch 121, train loss 0.0668026984684051\n",
      "epoch 122, train loss 0.00045019196945109537\n",
      "epoch 122, train loss 0.06572038999625615\n",
      "epoch 123, train loss 0.00042969083491091925\n",
      "epoch 123, train loss 0.07034169811578024\n",
      "epoch 124, train loss 0.0004104099990356536\n",
      "epoch 124, train loss 0.06958015073859503\n",
      "epoch 125, train loss 0.0003918025310942164\n",
      "epoch 125, train loss 0.0669625158466044\n",
      "epoch 126, train loss 0.00037441057354463116\n",
      "epoch 126, train loss 0.06302049282997374\n",
      "epoch 127, train loss 0.0003577403849848206\n",
      "epoch 127, train loss 0.06350052540027906\n",
      "epoch 128, train loss 0.0003419162623310787\n",
      "epoch 128, train loss 0.06733070378975263\n",
      "epoch 129, train loss 0.0003268037019999668\n",
      "epoch 129, train loss 0.06313765025328076\n",
      "epoch 130, train loss 0.0003124182357356721\n",
      "epoch 130, train loss 0.06223168933675403\n",
      "epoch 131, train loss 0.0002984688187661093\n",
      "epoch 131, train loss 0.06458928190644771\n",
      "epoch 132, train loss 0.0002854578506519338\n",
      "epoch 132, train loss 0.0582027126044508\n",
      "epoch 133, train loss 0.0002731884661544528\n",
      "epoch 133, train loss 0.061361277682913676\n",
      "epoch 134, train loss 0.0002616208807993976\n",
      "epoch 134, train loss 0.06350223034147233\n",
      "epoch 135, train loss 0.000250001087330193\n",
      "epoch 135, train loss 0.05985250069745003\n",
      "epoch 136, train loss 0.00023934928703099666\n",
      "epoch 136, train loss 0.05960194086508146\n",
      "epoch 137, train loss 0.00022931562136999139\n",
      "epoch 137, train loss 0.05642141200720318\n",
      "epoch 138, train loss 0.00021948355078209368\n",
      "epoch 138, train loss 0.06271339012753396\n",
      "epoch 139, train loss 0.0002099682509045427\n",
      "epoch 139, train loss 0.06146901201397654\n",
      "epoch 140, train loss 0.00020124834254457954\n",
      "epoch 140, train loss 0.05855057687158623\n",
      "epoch 141, train loss 0.00019272289258272698\n",
      "epoch 141, train loss 0.05979736918021762\n",
      "epoch 142, train loss 0.00018470166509764062\n",
      "epoch 142, train loss 0.06605391908023092\n",
      "epoch 143, train loss 0.00017674316191077527\n",
      "epoch 143, train loss 0.05882942055662473\n",
      "epoch 144, train loss 0.000169514685117137\n",
      "epoch 144, train loss 0.05778477116236611\n",
      "epoch 145, train loss 0.00016262693287220797\n",
      "epoch 145, train loss 0.05959732688608624\n",
      "epoch 146, train loss 0.00015574666816512092\n",
      "epoch 146, train loss 0.05775518851384284\n",
      "epoch 147, train loss 0.00014919540955729427\n",
      "epoch 147, train loss 0.06404070449726922\n",
      "epoch 148, train loss 0.00014335747474678866\n",
      "epoch 148, train loss 0.05262654647231102\n",
      "epoch 149, train loss 0.00013726352070022137\n",
      "epoch 149, train loss 0.05902428174066165\n",
      "epoch 150, train loss 0.00013162241763590524\n",
      "epoch 150, train loss 0.05933009460568428\n",
      "epoch 151, train loss 0.00012624091889140091\n",
      "epoch 151, train loss 0.05588179424641624\n",
      "epoch 152, train loss 0.0001211304636579746\n",
      "epoch 152, train loss 0.06480215528299885\n",
      "epoch 153, train loss 0.00011601608067784193\n",
      "epoch 153, train loss 0.06233346598252418\n",
      "epoch 154, train loss 0.00011127056126179736\n",
      "epoch 154, train loss 0.05267738305505306\n",
      "epoch 155, train loss 0.00010673392454110499\n",
      "epoch 155, train loss 0.05611718182880727\n",
      "epoch 156, train loss 0.00010238362463294632\n",
      "epoch 156, train loss 0.059013177951176964\n",
      "epoch 157, train loss 9.827494126049773e-05\n",
      "epoch 157, train loss 0.05508996711836921\n",
      "epoch 158, train loss 9.427585078695316e-05\n",
      "epoch 158, train loss 0.05826966047641777\n",
      "epoch 159, train loss 9.043743401499731e-05\n",
      "epoch 159, train loss 0.05676951271200937\n",
      "epoch 160, train loss 8.680334334106495e-05\n",
      "epoch 160, train loss 0.05311038504753794\n",
      "epoch 161, train loss 8.335826980386166e-05\n",
      "epoch 161, train loss 0.05600123394221541\n",
      "epoch 162, train loss 7.995651350707732e-05\n",
      "epoch 162, train loss 0.05207452296264588\n",
      "epoch 163, train loss 7.673223213743537e-05\n",
      "epoch 163, train loss 0.04895111646444079\n",
      "epoch 164, train loss 7.367315785294133e-05\n",
      "epoch 164, train loss 0.05091191999732502\n",
      "epoch 165, train loss 7.078274072790962e-05\n",
      "epoch 165, train loss 0.05042631758583917\n",
      "epoch 166, train loss 6.798372568381537e-05\n",
      "epoch 166, train loss 0.04865598787982312\n",
      "epoch 167, train loss 6.526342922514896e-05\n",
      "epoch 167, train loss 0.05650437703090055\n",
      "epoch 168, train loss 6.265974950529488e-05\n",
      "epoch 168, train loss 0.05595741698902751\n",
      "epoch 169, train loss 6.0234571488792195e-05\n",
      "epoch 169, train loss 0.06092048226486123\n",
      "epoch 170, train loss 5.787931900519493e-05\n",
      "epoch 170, train loss 0.057404373609830465\n",
      "epoch 171, train loss 5.556001471834154e-05\n",
      "epoch 171, train loss 0.048803368524189976\n",
      "epoch 172, train loss 5.340546837061762e-05\n",
      "epoch 172, train loss 0.05404541901652775\n",
      "epoch 173, train loss 5.131660041765177e-05\n",
      "epoch 173, train loss 0.05170652418146058\n",
      "epoch 174, train loss 4.9343299098028285e-05\n",
      "epoch 174, train loss 0.053787734566463366\n",
      "epoch 175, train loss 4.740251894136669e-05\n",
      "epoch 175, train loss 0.05863599165801018\n",
      "epoch 176, train loss 4.557011954371803e-05\n",
      "epoch 176, train loss 0.053481443740782286\n",
      "epoch 177, train loss 4.384874225093333e-05\n",
      "epoch 177, train loss 0.04760031313413665\n",
      "epoch 178, train loss 4.208012482166172e-05\n",
      "epoch 178, train loss 0.052121707489566196\n",
      "epoch 179, train loss 4.044855842717909e-05\n",
      "epoch 179, train loss 0.05072216586106353\n",
      "epoch 180, train loss 3.890683625026473e-05\n",
      "epoch 180, train loss 0.04975980594162903\n",
      "epoch 181, train loss 3.7410221603562285e-05\n",
      "epoch 181, train loss 0.05300747538133273\n",
      "epoch 182, train loss 3.60146197693659e-05\n",
      "epoch 182, train loss 0.046509961582838544\n",
      "epoch 183, train loss 3.459432778144551e-05\n",
      "epoch 183, train loss 0.04553796622961286\n",
      "epoch 184, train loss 3.326695254405162e-05\n",
      "epoch 184, train loss 0.04548779863213736\n",
      "epoch 185, train loss 3.2001274135721374e-05\n",
      "epoch 185, train loss 0.0542389482318882\n",
      "epoch 186, train loss 3.0781216472470465e-05\n",
      "epoch 186, train loss 0.05483779636403871\n",
      "epoch 187, train loss 2.961411932090645e-05\n",
      "epoch 187, train loss 0.04960648579493401\n",
      "epoch 188, train loss 2.8485890075061766e-05\n",
      "epoch 188, train loss 0.053135425680213504\n",
      "epoch 189, train loss 2.742173409575434e-05\n",
      "epoch 189, train loss 0.05066024730839427\n",
      "epoch 190, train loss 2.635318872177907e-05\n",
      "epoch 190, train loss 0.05398417273092838\n",
      "epoch 191, train loss 2.5371925648725e-05\n",
      "epoch 191, train loss 0.052451633892598604\n",
      "epoch 192, train loss 2.4390980869943704e-05\n",
      "epoch 192, train loss 0.05393905375921537\n",
      "epoch 193, train loss 2.348219707542624e-05\n",
      "epoch 193, train loss 0.055217219457503346\n",
      "epoch 194, train loss 2.259460416098591e-05\n",
      "epoch 194, train loss 0.057658578490927107\n",
      "epoch 195, train loss 2.1720225280631215e-05\n",
      "epoch 195, train loss 0.04971978387662342\n",
      "epoch 196, train loss 2.090534897953538e-05\n",
      "epoch 196, train loss 0.048236248689511464\n",
      "epoch 197, train loss 2.01320585296748e-05\n",
      "epoch 197, train loss 0.05002933099038071\n",
      "epoch 198, train loss 1.9372278695791177e-05\n",
      "epoch 198, train loss 0.04734465234454662\n",
      "epoch 199, train loss 1.862713794426305e-05\n",
      "epoch 199, train loss 0.04927106115907904\n",
      "epoch 200, train loss 1.7924636065597748e-05\n",
      "epoch 200, train loss 0.04700986706903056\n"
     ]
    }
   ],
   "source": [
    "n_epochs=200\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model = model.float()\n",
    "    model_drop = model_drop.float()\n",
    "    # TRAINING\n",
    "    loss_value = 0.0\n",
    "    loss_drop_value = 0.0\n",
    "    for x, y in trainloader:\n",
    "        #train mode\n",
    "        model.train()\n",
    "        model_drop.train()\n",
    "        #clear gradient\n",
    "        optimizer_ofit.zero_grad()\n",
    "        optimizer_drop.zero_grad()\n",
    "        #make a prediction for both models\n",
    "        yhat = model(data_set.x)\n",
    "        yhat_drop = model_drop(data_set.x)\n",
    "        #calculate the lossf or both models\n",
    "        loss = criterion(yhat, data_set.y)\n",
    "        loss_drop = criterion(yhat_drop, data_set.y)\n",
    "        #accumulate loss for further analysis for both models\n",
    "        loss_value += loss.item()\n",
    "        loss_drop_value += loss_drop.item()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        loss_drop.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer_ofit.step()\n",
    "        optimizer_drop.step()\n",
    "        #store the loss for the training data for both models\n",
    "    loss_value = loss_value / len(trainloader)\n",
    "    loss_drop_value = loss_drop_value / len(trainloader)\n",
    "\n",
    "    LOSS['training data no dropout'].append(loss_value)\n",
    "    LOSS['training data dropout'].append(loss_drop_value)\n",
    "    print('epoch {}, train loss {}'.format(epoch, loss_value))\n",
    "    print('epoch {}, train loss {}'.format(epoch, loss_drop_value))\n",
    "\n",
    "    # # VALIDATION\n",
    "    # with torch.no_grad():\n",
    "    #     for x, y in trainloader:\n",
    "    #         model_drop.eval()\n",
    "    #         model_drop.train()\n",
    "    #         #make a prediction for both models\n",
    "    #         yhat = model(data_set.x)\n",
    "    #         yhat_drop = model_drop(data_set.x)\n",
    "    #         #calculate the lossf or both models\n",
    "    #         loss = criterion(yhat, data_set.y)\n",
    "    #         loss_drop = criterion(yhat_drop, data_set.y)\n",
    "    #         #store the loss for the validation data for both models\n",
    "    #         LOSS['validation data no dropout'].append(loss.item())\n",
    "    #         LOSS['validation data dropout'].append(loss_drop.item())\n",
    "    #         print('epoch {}, test loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,(n_epochs+1),1), LOSS['training data no dropout'], 'r--')\n",
    "plt.legend(['training data, no dropout', 'training data, dropout'])\n",
    "plt.xlabel('epochs')\n",
    "plt.xlim([0, (n_epochs+1)])\n",
    "plt.xticks(np.arange(0,(n_epochs+1),20))\n",
    "plt.ylabel('loss')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,(n_epochs+1),1), LOSS['training data dropout'], 'r--')\n",
    "plt.legend(['training data, dropout'])\n",
    "plt.xlabel('epochs')\n",
    "plt.xlim([0, (n_epochs+1)])\n",
    "plt.xticks(np.arange(0,(n_epochs+1),20))\n",
    "plt.ylabel('loss')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model(x_val)\n",
    "z_dropout = model_drop(x_val)\n",
    "\n",
    "_,yhat=torch.max(z.data,1)\n",
    "_,yhat_dropout=torch.max(z_dropout.data,1)\n",
    "\n",
    "eval_matrix = (pd.crosstab(y_val, yhat))\n",
    "eval_matrix_dropout = (pd.crosstab(y_val, yhat_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3503184713375796"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eval_matrix[0][0]+eval_matrix[1][1]+eval_matrix[2][2])/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3885350318471338"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eval_matrix_dropout[0][0]+eval_matrix_dropout[1][1]+eval_matrix_dropout[2][2])/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary WITHOUT dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stationary</th>\n",
       "      <th>Go-forward</th>\n",
       "      <th>Go-right</th>\n",
       "      <th>Go-backward</th>\n",
       "      <th>Go-left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.82166</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.90446</td>\n",
       "      <td>0.88535</td>\n",
       "      <td>0.88535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGF</th>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.73057</td>\n",
       "      <td>0.87304</td>\n",
       "      <td>0.89092</td>\n",
       "      <td>0.79868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGM</th>\n",
       "      <td>0.75624</td>\n",
       "      <td>0.83959</td>\n",
       "      <td>0.90121</td>\n",
       "      <td>0.88538</td>\n",
       "      <td>0.86565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.67336</td>\n",
       "      <td>0.76408</td>\n",
       "      <td>0.87627</td>\n",
       "      <td>0.88548</td>\n",
       "      <td>0.81284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUPR</th>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.82364</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>0.74106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCD</th>\n",
       "      <td>0.01911</td>\n",
       "      <td>0.00955</td>\n",
       "      <td>0.00318</td>\n",
       "      <td>0.03185</td>\n",
       "      <td>0.01911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BM</th>\n",
       "      <td>0.34672</td>\n",
       "      <td>0.52816</td>\n",
       "      <td>0.75255</td>\n",
       "      <td>0.77096</td>\n",
       "      <td>0.62568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEN</th>\n",
       "      <td>0.63641</td>\n",
       "      <td>0.54696</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.34448</td>\n",
       "      <td>0.37478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR</th>\n",
       "      <td>0.17834</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.09554</td>\n",
       "      <td>0.11465</td>\n",
       "      <td>0.11465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F0.5</th>\n",
       "      <td>0.51587</td>\n",
       "      <td>0.48611</td>\n",
       "      <td>0.82938</td>\n",
       "      <td>0.72093</td>\n",
       "      <td>0.7764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.48148</td>\n",
       "      <td>0.51852</td>\n",
       "      <td>0.82353</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.73529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>0.45139</td>\n",
       "      <td>0.55556</td>\n",
       "      <td>0.81776</td>\n",
       "      <td>0.83784</td>\n",
       "      <td>0.69832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDR</th>\n",
       "      <td>0.45833</td>\n",
       "      <td>0.53333</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>0.31111</td>\n",
       "      <td>0.19355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.41667</td>\n",
       "      <td>0.18605</td>\n",
       "      <td>0.11429</td>\n",
       "      <td>0.32432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOR</th>\n",
       "      <td>0.12782</td>\n",
       "      <td>0.03521</td>\n",
       "      <td>0.06957</td>\n",
       "      <td>0.03571</td>\n",
       "      <td>0.09524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.08661</td>\n",
       "      <td>0.05517</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.11475</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.48448</td>\n",
       "      <td>0.52175</td>\n",
       "      <td>0.82359</td>\n",
       "      <td>0.78113</td>\n",
       "      <td>0.73817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>0.34672</td>\n",
       "      <td>0.52816</td>\n",
       "      <td>0.75255</td>\n",
       "      <td>0.77096</td>\n",
       "      <td>0.62568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.62913</td>\n",
       "      <td>0.74239</td>\n",
       "      <td>0.87406</td>\n",
       "      <td>0.88548</td>\n",
       "      <td>0.80118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBA</th>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.35191</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.78444</td>\n",
       "      <td>0.46581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICSI</th>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.64729</td>\n",
       "      <td>0.5746</td>\n",
       "      <td>0.48213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>1.50321</td>\n",
       "      <td>2.61012</td>\n",
       "      <td>1.60532</td>\n",
       "      <td>1.62768</td>\n",
       "      <td>1.77483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0.31707</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.63265</td>\n",
       "      <td>0.5814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS</th>\n",
       "      <td>2.83472</td>\n",
       "      <td>6.10556</td>\n",
       "      <td>3.04264</td>\n",
       "      <td>3.09016</td>\n",
       "      <td>3.42197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCEN</th>\n",
       "      <td>0.74774</td>\n",
       "      <td>0.64459</td>\n",
       "      <td>0.46099</td>\n",
       "      <td>0.47582</td>\n",
       "      <td>0.50041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>114</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLR</th>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.19822</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.34139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.87218</td>\n",
       "      <td>0.96479</td>\n",
       "      <td>0.93043</td>\n",
       "      <td>0.96429</td>\n",
       "      <td>0.90476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC</th>\n",
       "      <td>0.54167</td>\n",
       "      <td>0.58333</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.88571</td>\n",
       "      <td>0.80645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OOC</th>\n",
       "      <td>0.48448</td>\n",
       "      <td>0.52175</td>\n",
       "      <td>0.82359</td>\n",
       "      <td>0.78113</td>\n",
       "      <td>0.73817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP</th>\n",
       "      <td>0.4652</td>\n",
       "      <td>0.68064</td>\n",
       "      <td>0.83334</td>\n",
       "      <td>0.88509</td>\n",
       "      <td>0.71661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLR</th>\n",
       "      <td>5.00303</td>\n",
       "      <td>10.57292</td>\n",
       "      <td>13.25581</td>\n",
       "      <td>7.71837</td>\n",
       "      <td>13.51351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.54167</td>\n",
       "      <td>0.46667</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.68889</td>\n",
       "      <td>0.80645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.19108</td>\n",
       "      <td>0.07643</td>\n",
       "      <td>0.27389</td>\n",
       "      <td>0.22293</td>\n",
       "      <td>0.23567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACC</th>\n",
       "      <td>0.02921</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.07327</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.04653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACCU</th>\n",
       "      <td>0.02958</td>\n",
       "      <td>0.00739</td>\n",
       "      <td>0.07328</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>0.0469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>116</td>\n",
       "      <td>137</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.91339</td>\n",
       "      <td>0.94483</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>0.88525</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TON</th>\n",
       "      <td>133</td>\n",
       "      <td>142</td>\n",
       "      <td>115</td>\n",
       "      <td>112</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOP</th>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.43333</td>\n",
       "      <td>0.58333</td>\n",
       "      <td>0.81395</td>\n",
       "      <td>0.88571</td>\n",
       "      <td>0.67568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.34672</td>\n",
       "      <td>0.52816</td>\n",
       "      <td>0.75255</td>\n",
       "      <td>0.77096</td>\n",
       "      <td>0.62568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dInd</th>\n",
       "      <td>0.57325</td>\n",
       "      <td>0.4203</td>\n",
       "      <td>0.19592</td>\n",
       "      <td>0.16196</td>\n",
       "      <td>0.32816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sInd</th>\n",
       "      <td>0.59465</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.86147</td>\n",
       "      <td>0.88548</td>\n",
       "      <td>0.76796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Stationary Go-forward  Go-right Go-backward   Go-left\n",
       "Class                                                      \n",
       "ACC      0.82166     0.9172   0.90446     0.88535   0.88535\n",
       "AGF       0.6303    0.73057   0.87304     0.89092   0.79868\n",
       "AGM      0.75624    0.83959   0.90121     0.88538   0.86565\n",
       "AUC      0.67336    0.76408   0.87627     0.88548   0.81284\n",
       "AUPR      0.4875      0.525   0.82364      0.7873   0.74106\n",
       "BCD      0.01911    0.00955   0.00318     0.03185   0.01911\n",
       "BM       0.34672    0.52816   0.75255     0.77096   0.62568\n",
       "CEN      0.63641    0.54696    0.3162     0.34448   0.37478\n",
       "ERR      0.17834     0.0828   0.09554     0.11465   0.11465\n",
       "F0.5     0.51587    0.48611   0.82938     0.72093    0.7764\n",
       "F1       0.48148    0.51852   0.82353       0.775   0.73529\n",
       "F2       0.45139    0.55556   0.81776     0.83784   0.69832\n",
       "FDR      0.45833    0.53333   0.16667     0.31111   0.19355\n",
       "FN            17          5         8           4        12\n",
       "FNR      0.56667    0.41667   0.18605     0.11429   0.32432\n",
       "FOR      0.12782    0.03521   0.06957     0.03571   0.09524\n",
       "FP            11          8         7          14         6\n",
       "FPR      0.08661    0.05517    0.0614     0.11475      0.05\n",
       "G        0.48448    0.52175   0.82359     0.78113   0.73817\n",
       "GI       0.34672    0.52816   0.75255     0.77096   0.62568\n",
       "GM       0.62913    0.74239   0.87406     0.88548   0.80118\n",
       "IBA       0.2058    0.35191   0.66875     0.78444   0.46581\n",
       "ICSI      -0.025       0.05   0.64729      0.5746   0.48213\n",
       "IS       1.50321    2.61012   1.60532     1.62768   1.77483\n",
       "J        0.31707       0.35       0.7     0.63265    0.5814\n",
       "LS       2.83472    6.10556   3.04264     3.09016   3.42197\n",
       "MCEN     0.74774    0.64459   0.46099     0.47582   0.50041\n",
       "N            127        145       114         122       120\n",
       "NLR       0.6204      0.441   0.19822      0.1291   0.34139\n",
       "NPV      0.87218    0.96479   0.93043     0.96429   0.90476\n",
       "OC       0.54167    0.58333   0.83333     0.88571   0.80645\n",
       "OOC      0.48448    0.52175   0.82359     0.78113   0.73817\n",
       "OP        0.4652    0.68064   0.83334     0.88509   0.71661\n",
       "P             30         12        43          35        37\n",
       "PLR      5.00303   10.57292  13.25581     7.71837  13.51351\n",
       "POP          157        157       157         157       157\n",
       "PPV      0.54167    0.46667   0.83333     0.68889   0.80645\n",
       "PRE      0.19108    0.07643   0.27389     0.22293   0.23567\n",
       "RACC     0.02921     0.0073   0.07327      0.0639   0.04653\n",
       "RACCU    0.02958    0.00739   0.07328     0.06491    0.0469\n",
       "TN           116        137       107         108       114\n",
       "TNR      0.91339    0.94483    0.9386     0.88525      0.95\n",
       "TON          133        142       115         112       126\n",
       "TOP           24         15        42          45        31\n",
       "TP            13          7        35          31        25\n",
       "TPR      0.43333    0.58333   0.81395     0.88571   0.67568\n",
       "Y        0.34672    0.52816   0.75255     0.77096   0.62568\n",
       "dInd     0.57325     0.4203   0.19592     0.16196   0.32816\n",
       "sInd     0.59465     0.7028   0.86147     0.88548   0.76796"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['ACC'\n",
    "                    ,'AGF'\n",
    "                    ,'AGM'\n",
    "                    ,'AUC'\n",
    "                    ,'AUPR'\n",
    "                    ,'BCD'\n",
    "                    ,'BM'\n",
    "                    ,'CEN'\n",
    "                    ,'ERR'\n",
    "                    ,'F0.5'\n",
    "                    ,'F1'\n",
    "                    ,'F2'\n",
    "                    ,'FDR'\n",
    "                    ,'FN'\n",
    "                    ,'FNR'\n",
    "                    ,'FOR'\n",
    "                    ,'FP'\n",
    "                    ,'FPR'\n",
    "                    ,'G'\n",
    "                    ,'GI'\n",
    "                    ,'GM'\n",
    "                    ,'IBA'\n",
    "                    ,'ICSI'\n",
    "                    ,'IS'\n",
    "                    ,'J'\n",
    "                    ,'LS'\n",
    "                    ,'MCEN'\n",
    "                    ,'N'\n",
    "                    ,'NLR'\n",
    "                    ,'NPV'\n",
    "                    ,'OC'\n",
    "                    ,'OOC'\n",
    "                    ,'OP'\n",
    "                    ,'P'\n",
    "                    ,'PLR'\n",
    "                    ,'POP'\n",
    "                    ,'PPV'\n",
    "                    ,'PRE'\n",
    "                    ,'RACC'\n",
    "                    ,'RACCU'\n",
    "                    ,'TN'\n",
    "                    ,'TNR'\n",
    "                    ,'TON'\n",
    "                    ,'TOP'\n",
    "                    ,'TP'\n",
    "                    ,'TPR'\n",
    "                    ,'Y'\n",
    "                    ,'dInd'\n",
    "                    ,'sInd']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()\n",
    "inputs, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(inputs)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, x)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary WITH dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat_dropout))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm.plot(cmap=plt.cm.Greens,number_label=True,plot_lib=\"matplotlib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stationary</th>\n",
       "      <th>Go-forward</th>\n",
       "      <th>Go-right</th>\n",
       "      <th>Go-backward</th>\n",
       "      <th>Go-left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.83439</td>\n",
       "      <td>0.94904</td>\n",
       "      <td>0.89172</td>\n",
       "      <td>0.91083</td>\n",
       "      <td>0.89172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGF</th>\n",
       "      <td>0.71321</td>\n",
       "      <td>0.80516</td>\n",
       "      <td>0.87719</td>\n",
       "      <td>0.88072</td>\n",
       "      <td>0.81485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGM</th>\n",
       "      <td>0.79568</td>\n",
       "      <td>0.88546</td>\n",
       "      <td>0.89007</td>\n",
       "      <td>0.90375</td>\n",
       "      <td>0.87464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.73215</td>\n",
       "      <td>0.81954</td>\n",
       "      <td>0.87475</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.82635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUPR</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.80991</td>\n",
       "      <td>0.80618</td>\n",
       "      <td>0.7576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00955</td>\n",
       "      <td>0.00637</td>\n",
       "      <td>0.01592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BM</th>\n",
       "      <td>0.4643</td>\n",
       "      <td>0.63908</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEN</th>\n",
       "      <td>0.57807</td>\n",
       "      <td>0.41562</td>\n",
       "      <td>0.32855</td>\n",
       "      <td>0.30259</td>\n",
       "      <td>0.35478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR</th>\n",
       "      <td>0.16561</td>\n",
       "      <td>0.05096</td>\n",
       "      <td>0.10828</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.10828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F0.5</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.79295</td>\n",
       "      <td>0.79235</td>\n",
       "      <td>0.78788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.80899</td>\n",
       "      <td>0.80556</td>\n",
       "      <td>0.75362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.82569</td>\n",
       "      <td>0.81921</td>\n",
       "      <td>0.72222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDR</th>\n",
       "      <td>0.43333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.21739</td>\n",
       "      <td>0.21622</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.43333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.16279</td>\n",
       "      <td>0.17143</td>\n",
       "      <td>0.2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOR</th>\n",
       "      <td>0.10236</td>\n",
       "      <td>0.02759</td>\n",
       "      <td>0.06306</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.10236</td>\n",
       "      <td>0.02759</td>\n",
       "      <td>0.08772</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.80945</td>\n",
       "      <td>0.80587</td>\n",
       "      <td>0.75561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GI</th>\n",
       "      <td>0.4643</td>\n",
       "      <td>0.63908</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.71321</td>\n",
       "      <td>0.80516</td>\n",
       "      <td>0.87394</td>\n",
       "      <td>0.87991</td>\n",
       "      <td>0.81705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBA</th>\n",
       "      <td>0.34031</td>\n",
       "      <td>0.45007</td>\n",
       "      <td>0.70643</td>\n",
       "      <td>0.69228</td>\n",
       "      <td>0.50248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICSI</th>\n",
       "      <td>0.13333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.61982</td>\n",
       "      <td>0.61236</td>\n",
       "      <td>0.5152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>1.5683</td>\n",
       "      <td>3.1247</td>\n",
       "      <td>1.51472</td>\n",
       "      <td>1.81387</td>\n",
       "      <td>1.78561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0.39535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.67925</td>\n",
       "      <td>0.67442</td>\n",
       "      <td>0.60465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS</th>\n",
       "      <td>2.96556</td>\n",
       "      <td>8.72222</td>\n",
       "      <td>2.85743</td>\n",
       "      <td>3.51583</td>\n",
       "      <td>3.44764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCEN</th>\n",
       "      <td>0.70974</td>\n",
       "      <td>0.52594</td>\n",
       "      <td>0.47176</td>\n",
       "      <td>0.42595</td>\n",
       "      <td>0.47938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>114</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLR</th>\n",
       "      <td>0.48275</td>\n",
       "      <td>0.34279</td>\n",
       "      <td>0.17844</td>\n",
       "      <td>0.18346</td>\n",
       "      <td>0.31294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.89764</td>\n",
       "      <td>0.97241</td>\n",
       "      <td>0.93694</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.83721</td>\n",
       "      <td>0.82857</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OOC</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.80945</td>\n",
       "      <td>0.80587</td>\n",
       "      <td>0.75561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP</th>\n",
       "      <td>0.60837</td>\n",
       "      <td>0.76251</td>\n",
       "      <td>0.84881</td>\n",
       "      <td>0.85079</td>\n",
       "      <td>0.74209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLR</th>\n",
       "      <td>5.5359</td>\n",
       "      <td>24.16667</td>\n",
       "      <td>9.54419</td>\n",
       "      <td>12.63571</td>\n",
       "      <td>14.05405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78378</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE</th>\n",
       "      <td>0.19108</td>\n",
       "      <td>0.07643</td>\n",
       "      <td>0.27389</td>\n",
       "      <td>0.22293</td>\n",
       "      <td>0.23567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACC</th>\n",
       "      <td>0.03651</td>\n",
       "      <td>0.00584</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>0.05254</td>\n",
       "      <td>0.04803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACCU</th>\n",
       "      <td>0.03651</td>\n",
       "      <td>0.00584</td>\n",
       "      <td>0.08034</td>\n",
       "      <td>0.05258</td>\n",
       "      <td>0.04829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>114</td>\n",
       "      <td>141</td>\n",
       "      <td>104</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.89764</td>\n",
       "      <td>0.97241</td>\n",
       "      <td>0.91228</td>\n",
       "      <td>0.93443</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TON</th>\n",
       "      <td>127</td>\n",
       "      <td>145</td>\n",
       "      <td>111</td>\n",
       "      <td>120</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOP</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.56667</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>0.83721</td>\n",
       "      <td>0.82857</td>\n",
       "      <td>0.7027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.4643</td>\n",
       "      <td>0.63908</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dInd</th>\n",
       "      <td>0.44526</td>\n",
       "      <td>0.33447</td>\n",
       "      <td>0.18492</td>\n",
       "      <td>0.18354</td>\n",
       "      <td>0.30147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sInd</th>\n",
       "      <td>0.68515</td>\n",
       "      <td>0.76349</td>\n",
       "      <td>0.86924</td>\n",
       "      <td>0.87022</td>\n",
       "      <td>0.78683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Stationary Go-forward Go-right Go-backward   Go-left\n",
       "Class                                                     \n",
       "ACC      0.83439    0.94904  0.89172     0.91083   0.89172\n",
       "AGF      0.71321    0.80516  0.87719     0.88072   0.81485\n",
       "AGM      0.79568    0.88546  0.89007     0.90375   0.87464\n",
       "AUC      0.73215    0.81954  0.87475      0.8815   0.82635\n",
       "AUPR     0.56667    0.66667  0.80991     0.80618    0.7576\n",
       "BCD          0.0        0.0  0.00955     0.00637   0.01592\n",
       "BM        0.4643    0.63908  0.74949       0.763    0.6527\n",
       "CEN      0.57807    0.41562  0.32855     0.30259   0.35478\n",
       "ERR      0.16561    0.05096  0.10828     0.08917   0.10828\n",
       "F0.5     0.56667    0.66667  0.79295     0.79235   0.78788\n",
       "F1       0.56667    0.66667  0.80899     0.80556   0.75362\n",
       "F2       0.56667    0.66667  0.82569     0.81921   0.72222\n",
       "FDR      0.43333    0.33333  0.21739     0.21622    0.1875\n",
       "FN            13          4        7           6        11\n",
       "FNR      0.43333    0.33333  0.16279     0.17143    0.2973\n",
       "FOR      0.10236    0.02759  0.06306        0.05     0.088\n",
       "FP            13          4       10           8         6\n",
       "FPR      0.10236    0.02759  0.08772     0.06557      0.05\n",
       "G        0.56667    0.66667  0.80945     0.80587   0.75561\n",
       "GI        0.4643    0.63908  0.74949       0.763    0.6527\n",
       "GM       0.71321    0.80516  0.87394     0.87991   0.81705\n",
       "IBA      0.34031    0.45007  0.70643     0.69228   0.50248\n",
       "ICSI     0.13333    0.33333  0.61982     0.61236    0.5152\n",
       "IS        1.5683     3.1247  1.51472     1.81387   1.78561\n",
       "J        0.39535        0.5  0.67925     0.67442   0.60465\n",
       "LS       2.96556    8.72222  2.85743     3.51583   3.44764\n",
       "MCEN     0.70974    0.52594  0.47176     0.42595   0.47938\n",
       "N            127        145      114         122       120\n",
       "NLR      0.48275    0.34279  0.17844     0.18346   0.31294\n",
       "NPV      0.89764    0.97241  0.93694        0.95     0.912\n",
       "OC       0.56667    0.66667  0.83721     0.82857    0.8125\n",
       "OOC      0.56667    0.66667  0.80945     0.80587   0.75561\n",
       "OP       0.60837    0.76251  0.84881     0.85079   0.74209\n",
       "P             30         12       43          35        37\n",
       "PLR       5.5359   24.16667  9.54419    12.63571  14.05405\n",
       "POP          157        157      157         157       157\n",
       "PPV      0.56667    0.66667  0.78261     0.78378    0.8125\n",
       "PRE      0.19108    0.07643  0.27389     0.22293   0.23567\n",
       "RACC     0.03651    0.00584  0.08025     0.05254   0.04803\n",
       "RACCU    0.03651    0.00584  0.08034     0.05258   0.04829\n",
       "TN           114        141      104         114       114\n",
       "TNR      0.89764    0.97241  0.91228     0.93443      0.95\n",
       "TON          127        145      111         120       125\n",
       "TOP           30         12       46          37        32\n",
       "TP            17          8       36          29        26\n",
       "TPR      0.56667    0.66667  0.83721     0.82857    0.7027\n",
       "Y         0.4643    0.63908  0.74949       0.763    0.6527\n",
       "dInd     0.44526    0.33447  0.18492     0.18354   0.30147\n",
       "sInd     0.68515    0.76349  0.86924     0.87022   0.78683"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(actual_vector=np.array(y_val).astype(int), predict_vector=np.array(yhat_dropout))\n",
    "\n",
    "name = \"cm\"\n",
    "cm.save_csv(name=name)\n",
    "name += \".csv\"\n",
    "cm_stats = pd.read_csv(name, index_col='Class')\n",
    "cm_stats = cm_stats.rename(columns={'0': 'Stationary', '1': 'Go-forward', '2': 'Go-right', '3': 'Go-backward', '4': 'Go-left'})\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats = cm_stats[['ACC'\n",
    "                    ,'AGF'\n",
    "                    ,'AGM'\n",
    "                    ,'AUC'\n",
    "                    ,'AUPR'\n",
    "                    ,'BCD'\n",
    "                    ,'BM'\n",
    "                    ,'CEN'\n",
    "                    ,'ERR'\n",
    "                    ,'F0.5'\n",
    "                    ,'F1'\n",
    "                    ,'F2'\n",
    "                    ,'FDR'\n",
    "                    ,'FN'\n",
    "                    ,'FNR'\n",
    "                    ,'FOR'\n",
    "                    ,'FP'\n",
    "                    ,'FPR'\n",
    "                    ,'G'\n",
    "                    ,'GI'\n",
    "                    ,'GM'\n",
    "                    ,'IBA'\n",
    "                    ,'ICSI'\n",
    "                    ,'IS'\n",
    "                    ,'J'\n",
    "                    ,'LS'\n",
    "                    ,'MCEN'\n",
    "                    ,'N'\n",
    "                    ,'NLR'\n",
    "                    ,'NPV'\n",
    "                    ,'OC'\n",
    "                    ,'OOC'\n",
    "                    ,'OP'\n",
    "                    ,'P'\n",
    "                    ,'PLR'\n",
    "                    ,'POP'\n",
    "                    ,'PPV'\n",
    "                    ,'PRE'\n",
    "                    ,'RACC'\n",
    "                    ,'RACCU'\n",
    "                    ,'TN'\n",
    "                    ,'TNR'\n",
    "                    ,'TON'\n",
    "                    ,'TOP'\n",
    "                    ,'TP'\n",
    "                    ,'TPR'\n",
    "                    ,'Y'\n",
    "                    ,'dInd'\n",
    "                    ,'sInd']]\n",
    "cm_stats = cm_stats.T\n",
    "cm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()\n",
    "inputs, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(inputs)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model_drop, x)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86f19e771fb0dadfe63e3726ad5c2cfa9fd6d93df242c0f577dd3eb092bc288c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('detectron2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
